{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Working with Real Data\n",
    "\n",
    "In the real world, data doesn't come in nice pre-packaged tensors. It comes in CSV files, image folders, text documents, and databases. This notebook teaches you how to handle real-world data in PyTorch.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand `Dataset` and `DataLoader` classes\n",
    "- Create custom datasets for CSV and image data\n",
    "- Use DataLoaders for batching and shuffling\n",
    "- Apply data transformations and augmentation\n",
    "\n",
    "---\n",
    "\n",
    "## The PyTorch Data Pipeline\n",
    "\n",
    "The standard pipeline for handling data in PyTorch involves two main classes:\n",
    "\n",
    "1. **`torch.utils.data.Dataset`**: Stores the samples and their corresponding labels.\n",
    "2. **`torch.utils.data.DataLoader`**: Wraps an iterable around the Dataset to enable easy access to the samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Dataset from CSV\n",
    "\n",
    "Let's simulate a common scenario: you have a CSV file with features and labels.\n",
    "\n",
    "First, we'll create a dummy CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy CSV file\n",
    "data = {\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'label': np.random.randint(0, 2, 100)  # Binary classification\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('dummy_data.csv', index=False)\n",
    "print(\"Created dummy_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a custom Dataset class to read this CSV.\n",
    "\n",
    "A custom Dataset must implement three functions:\n",
    "- `__init__`: Initialize data, download, etc.\n",
    "- `__len__`: Return the size of the dataset\n",
    "- `__getitem__`: Return one sample (feature, label) at the given index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get features (columns 0-2)\n",
    "        features = self.data.iloc[idx, 0:3].values.astype(np.float32)\n",
    "        # Get label (column 3)\n",
    "        label = self.data.iloc[idx, 3]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        features = torch.tensor(features)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return features, label\n",
    "\n",
    "# Test the dataset\n",
    "dataset = CSVDataset('dummy_data.csv')\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "features, label = dataset[0]\n",
    "print(f\"First sample features: {features}\")\n",
    "print(f\"First sample label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using DataLoader\n",
    "\n",
    "The `DataLoader` handles batching, shuffling, and parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Iterate through the dataloader\n",
    "print(\"Iterating through DataLoader:\")\n",
    "for i, (features, labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Features shape: {features.shape}\")\n",
    "    print(f\"  Labels: {labels}\")\n",
    "    if i == 2:  # Stop after 3 batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Data and Transforms\n",
    "\n",
    "For images, we often use `torchvision.transforms` for preprocessing and augmentation.\n",
    "\n",
    "Common transforms:\n",
    "- `Resize`: Change image size\n",
    "- `ToTensor`: Convert image to tensor (scales to 0-1, moves channels first)\n",
    "- `Normalize`: Normalize with mean and std\n",
    "- `RandomHorizontalFlip`: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Augmentation\n",
    "    transforms.ToTensor(),  # Converts [0, 255] to [0, 1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "print(\"Transforms defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ImageFolder\n",
    "\n",
    "If your images are organized in folders by class (e.g., `data/cats/`, `data/dogs/`), you can use `torchvision.datasets.ImageFolder`.\n",
    "\n",
    "```python\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# dataset = ImageFolder(root='path/to/data', transform=transform)\n",
    "```\n",
    "\n",
    "This automatically assigns labels based on folder names!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Dataset Class**: Implement `__len__` and `__getitem__` to handle your custom data.\n",
    "2. **DataLoader**: Use this for efficient batching and shuffling.\n",
    "3. **Transforms**: Essential for image preprocessing and augmentation.\n",
    "4. **ImageFolder**: The easiest way to load classification datasets organized by folder.\n",
    "\n",
    "**Clean up**: Let's remove the dummy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('dummy_data.csv'):\n",
    "    os.remove('dummy_data.csv')\n",
    "    print(\"Removed dummy_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
