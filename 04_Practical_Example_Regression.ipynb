{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a190944",
   "metadata": {},
   "source": [
    "# PyTorch Deep Dive: Practical Example - Regression\n",
    "\n",
    "We have learned the theory. Now let's solve a real problem.\n",
    "\n",
    "In this notebook, we will predict a **continuous value** (e.g., House Price). This is called **Regression**.\n",
    "\n",
    "## Learning Objectives\n",
    "- **The Vocabulary**: What is \"Regression\", \"Overfitting\", and \"Underfitting\"?\n",
    "- **The Intuition**: The \"Goldilocks\" analogy for model complexity.\n",
    "- **The Practice**: Building a model to predict non-linear data.\n",
    "- **The Visual**: Seeing the model fit the curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed1e04",
   "metadata": {},
   "source": [
    "## Part 1: The Vocabulary (Definitions First)\n",
    "\n",
    "Before we code, let's define the problem type and the pitfalls.\n",
    "\n",
    "### 1. Regression vs Classification\n",
    "- **Regression**: Predicting a quantity (How much?).\n",
    "    - Example: Price, Temperature, Height.\n",
    "    - Output: A single number (e.g., 345.2).\n",
    "- **Classification**: Predicting a category (Which one?).\n",
    "    - Example: Cat vs Dog, Spam vs Not Spam.\n",
    "    - Output: A probability (e.g., 80% Cat).\n",
    "\n",
    "### 2. Overfitting (Memorization)\n",
    "- When the model learns the *noise* instead of the *pattern*.\n",
    "- It does great on training data but fails on new data.\n",
    "- Analogy: Memorizing the answers to the practice test but failing the real exam.\n",
    "\n",
    "### 3. Underfitting (Oversimplification)\n",
    "- When the model is too simple to capture the pattern.\n",
    "- It does poorly on everything.\n",
    "- Analogy: Trying to explain Quantum Physics using only addition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f0348",
   "metadata": {},
   "source": [
    "## Part 2: The Intuition (Goldilocks Principle)\n",
    "\n",
    "Building a model is like fitting a bed for Goldilocks.\n",
    "\n",
    "- **Too Hard (Underfitting)**: A straight line trying to fit a curve. It misses the point.\n",
    "- **Too Soft (Overfitting)**: A squiggly line that touches every single dot. It's too sensitive to noise.\n",
    "- **Just Right (Generalization)**: A smooth curve that captures the trend.\n",
    "\n",
    "Our goal is to find the \"Just Right\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f6df4",
   "metadata": {},
   "source": [
    "## Part 3: The Data (Non-Linear)\n",
    "\n",
    "Let's create some data that isn't a straight line. Let's use a sine wave with some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data: y = sin(x)\n",
    "x = torch.linspace(-5, 5, 100).view(-1, 1)\n",
    "y = torch.sin(x) + 0.1 * torch.randn(x.size())\n",
    "\n",
    "plt.scatter(x.numpy(), y.numpy())\n",
    "plt.title(\"Noisy Sine Wave\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1ba99",
   "metadata": {},
   "source": [
    "## Part 4: The Model (Going Deeper)\n",
    "\n",
    "A single Linear Layer cannot learn a sine wave. It can only learn a straight line.\n",
    "To learn curves, we need **Hidden Layers** and **Activation Functions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a86fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layer 1: Expand to 50 neurons (Add complexity)\n",
    "        self.hidden1 = nn.Linear(1, 50)\n",
    "        # Layer 2: Another 50 neurons (More complexity)\n",
    "        self.hidden2 = nn.Linear(50, 50)\n",
    "        # Output Layer: Back to 1 number\n",
    "        self.output = nn.Linear(50, 1)\n",
    "        # Activation: ReLU (The bendy part)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = SineNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam is often better than SGD\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f38c6d",
   "metadata": {},
   "source": [
    "## Part 5: Training (The Loop)\n",
    "\n",
    "We use the same 5-step loop as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward\n",
    "    pred = model(x)\n",
    "    # 2. Loss\n",
    "    loss = criterion(pred, y)\n",
    "    # 3. Zero\n",
    "    optimizer.zero_grad()\n",
    "    # 4. Backward\n",
    "    loss.backward()\n",
    "    # 5. Step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd10b1",
   "metadata": {},
   "source": [
    "## Part 6: Visualization (The Moment of Truth)\n",
    "\n",
    "Did our model learn the curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), y.numpy(), label=\"Data\")\n",
    "with torch.no_grad():\n",
    "    plt.plot(x.numpy(), model(x).numpy(), color='red', label=\"Prediction\", linewidth=3)\n",
    "plt.title(\"Regression: Fitting a Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70212aa8",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "1. **Regression** = Predicting a continuous number.\n",
    "2. **Hidden Layers** = Allow the model to learn complex, non-linear patterns.\n",
    "3. **Overfitting** = Memorizing noise (Bad).\n",
    "4. **Underfitting** = Failing to capture the pattern (Bad).\n",
    "\n",
    "Next, we will tackle the other main type of problem: **Classification**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
