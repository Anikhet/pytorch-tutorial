{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12d7ac8",
   "metadata": {},
   "source": [
    "# PyTorch Deep Dive: Introduction and Tensors\n",
    "\n",
    "Welcome to the absolute foundation of Deep Learning. \n",
    "\n",
    "Before we write code, we need to define the **Objects** we are working with.\n",
    "\n",
    "## Learning Objectives\n",
    "- **The Vocabulary**: What is a \"Tensor\", \"Scalar\", \"Vector\", and \"Matrix\"?\n",
    "- **The Intuition**: Tensors as \"Excel Sheets on Steroids\".\n",
    "- **The Hardware**: CPU vs GPU (Minivan vs Sports Car).\n",
    "- **The Mechanics**: Shapes, Dtypes, and Broadcasting.\n",
    "- **The Deep Dive**: Strides and Memory Layout (What actually happens in RAM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d922660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84392d28",
   "metadata": {},
   "source": [
    "## Part 1: The Vocabulary (Definitions First)\n",
    "\n",
    "In Data Science, we have specific names for containers of numbers based on their dimensions.\n",
    "\n",
    "### 1. Scalar (0D)\n",
    "- A single number.\n",
    "- Example: `7`, `3.14`.\n",
    "- Use case: A loss value, a learning rate.\n",
    "\n",
    "### 2. Vector (1D)\n",
    "- A list of numbers.\n",
    "- Example: `[1, 2, 3]`.\n",
    "- Use case: A row of data, a bias term.\n",
    "\n",
    "### 3. Matrix (2D)\n",
    "- A grid of numbers (Rows and Columns).\n",
    "- Example: An Excel sheet, a black-and-white image.\n",
    "- Use case: A dataset, weights of a linear layer.\n",
    "\n",
    "### 4. Tensor (ND)\n",
    "- A generic term for N-dimensional arrays (3D, 4D, etc.).\n",
    "- Example: A color image (Height x Width x 3 Channels), a video (Time x H x W x C).\n",
    "- Use case: Complex data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233bafd",
   "metadata": {},
   "source": [
    "## Part 2: The Intuition (Excel on Steroids)\n",
    "\n",
    "Now that we know the terms, let's visualize them.\n",
    "\n",
    "- **2D Tensor**: Imagine a single Excel sheet.\n",
    "- **3D Tensor**: Imagine a **Workbook** containing multiple Excel sheets.\n",
    "- **4D Tensor**: Imagine a **Filing Cabinet** containing multiple Workbooks.\n",
    "- **5D Tensor**: Imagine a **Library** containing multiple Filing Cabinets.\n",
    "\n",
    "PyTorch Tensors are just these containers, but optimized for math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6a8ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 7 (Shape: torch.Size([]))\n",
      "Vector: tensor([7, 2, 5]) (Shape: torch.Size([3]))\n",
      "Matrix:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) (Shape: torch.Size([2, 2]))\n",
      "3D Tensor Shape: torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensor (Scalar)\n",
    "scalar = torch.tensor(7)\n",
    "print(f\"Scalar: {scalar.item()} (Shape: {scalar.shape})\")\n",
    "\n",
    "# 1D Tensor (Vector)\n",
    "vector = torch.tensor([7, 2, 5])\n",
    "print(f\"Vector: {vector} (Shape: {vector.shape})\")\n",
    "\n",
    "# 2D Tensor (Matrix)\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"Matrix:\\n{matrix} (Shape: {matrix.shape})\")\n",
    "\n",
    "# 3D Tensor (Image-like)\n",
    "tensor3d = torch.rand(3, 4, 4) # 3 Channels, 4x4 pixels\n",
    "print(f\"3D Tensor Shape: {tensor3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c8263",
   "metadata": {},
   "source": [
    "## Part 3: The Hardware (Minivan vs Sports Car)\n",
    "\n",
    "Why do we use PyTorch Tensors instead of Python lists or NumPy arrays?\n",
    "\n",
    "**The GPU.**\n",
    "\n",
    "- **CPU (Central Processing Unit)**: Like a **Minivan**. It can carry a few things (instructions) very quickly and flexibly. Good for sequential logic.\n",
    "- **GPU (Graphics Processing Unit)**: Like a **Train** or **Fleet of Sports Cars**. It can carry MASSIVE amounts of data at once, but it's hard to turn. Good for parallel math (matrix multiplication).\n",
    "\n",
    "PyTorch Tensors can live on the GPU. NumPy arrays cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387cff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "x is on: cpu\n",
      "x_gpu is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Move tensor to GPU\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_gpu = x.to(device)\n",
    "\n",
    "print(f\"x is on: {x.device}\")\n",
    "print(f\"x_gpu is on: {x_gpu.device}\")\n",
    "\n",
    "# Note: You cannot add a CPU tensor to a GPU tensor. They live in different worlds!\n",
    "# x + x_gpu # This would error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84446d6c",
   "metadata": {},
   "source": [
    "## Part 4: The Mechanics (Broadcasting)\n",
    "\n",
    "Broadcasting is magic. It allows you to do math on tensors of different shapes.\n",
    "\n",
    "Imagine you have a matrix of students' scores (Rows=Students, Cols=Subjects).\n",
    "You want to add 5 bonus points to **every** score.\n",
    "\n",
    "You don't need to create a matrix of 5s. You just add `5`.\n",
    "PyTorch \"broadcasts\" (stretches) the `5` to match the matrix shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1654a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix + 5:\n",
      " tensor([[15, 25, 35],\n",
      "        [45, 55, 65]])\n",
      "Matrix + Vector:\n",
      " tensor([[11, 22, 33],\n",
      "        [41, 52, 63]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[10, 20, 30], \n",
    "                       [40, 50, 60]])\n",
    "\n",
    "# Add scalar (Broadcasting 5 to match 2x3)\n",
    "print(\"Matrix + 5:\\n\", matrix + 5)\n",
    "\n",
    "# Add vector (Broadcasting [1, 2, 3] to every row)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(\"Matrix + Vector:\\n\", matrix + vector)\n",
    "\n",
    "# Visualizing what happened:\n",
    "# [10, 20, 30] + [1, 2, 3] = [11, 22, 33]\n",
    "# [40, 50, 60] + [1, 2, 3] = [41, 52, 63]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7610967",
   "metadata": {},
   "source": [
    "## Part 5: The Deep Dive (Strides & Memory)\n",
    "\n",
    "Here is the secret: **A Tensor is just a 1D array in memory.**\n",
    "\n",
    "The \"shape\" (rows, columns) is an illusion created by **Strides**.\n",
    "\n",
    "- **Stride**: How many steps in memory do I need to jump to get to the next element in this dimension?\n",
    "\n",
    "Example: Matrix 2x3\n",
    "`[[1, 2, 3], [4, 5, 6]]`\n",
    "\n",
    "In memory (RAM): `[1, 2, 3, 4, 5, 6]`\n",
    "\n",
    "To go from `1` to `2` (next column), jump 1 step.\n",
    "To go from `1` to `4` (next row), jump 3 steps.\n",
    "\n",
    "Stride = `(3, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3])\n",
      "Stride: (3, 1)\n",
      "\n",
      "Transposed Shape: torch.Size([3, 2])\n",
      "Transposed Stride: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(f\"Shape: {t.shape}\")\n",
    "print(f\"Stride: {t.stride()}\")\n",
    "\n",
    "# Transpose it (swap rows/cols)\n",
    "t_T = t.t()\n",
    "print(f\"\\nTransposed Shape: {t_T.shape}\")\n",
    "print(f\"Transposed Stride: {t_T.stride()}\")\n",
    "\n",
    "# Notice: The DATA in memory didn't move! PyTorch just swapped the strides.\n",
    "# This makes transposing instant, even for huge matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Tensor Operations (FAANG Interview Essentials)\n",
    "\n",
    "### Views vs Copies - Critical Interview Topic\n",
    "\n",
    "**View**: A new tensor object that shares the same underlying data.\n",
    "**Copy**: A completely independent tensor with its own memory.\n",
    "\n",
    "This distinction is CRITICAL for:\n",
    "1. Memory efficiency (views are nearly free)\n",
    "2. Bug prevention (modifying views affects originals)\n",
    "3. Understanding when `contiguous()` is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "euw3t11ooll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([1, 2, 3, 4, 5, 6])\n",
      "View:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Same memory? True\n",
      "\n",
      "After modifying view[0,0] = 999:\n",
      "Original: tensor([999,   2,   3,   4,   5,   6])\n",
      "View:\n",
      "tensor([[999,   2,   3],\n",
      "        [  4,   5,   6]])\n",
      "\n",
      "After cloning and modifying copy[0] = 888:\n",
      "Original: tensor([1, 2, 3, 4, 5, 6])\n",
      "Copy: tensor([888,   2,   3,   4,   5,   6])\n",
      "\n",
      "ðŸ”‘ FAANG Interview Tip: Always use .clone() when you need to modify a tensor independently!\n"
     ]
    }
   ],
   "source": [
    "# Views vs Copies - FAANG Interview Classic\n",
    "\n",
    "original = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# View: shares memory with original\n",
    "view = original.view(2, 3)\n",
    "print(f\"Original: {original}\")\n",
    "print(f\"View:\\n{view}\")\n",
    "print(f\"Same memory? {original.data_ptr() == view.data_ptr()}\")  # True!\n",
    "\n",
    "# Modify the view - affects original!\n",
    "view[0, 0] = 999\n",
    "print(f\"\\nAfter modifying view[0,0] = 999:\")\n",
    "print(f\"Original: {original}\")  # Also changed!\n",
    "print(f\"View:\\n{view}\")\n",
    "\n",
    "# Clone: creates independent copy\n",
    "original = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "copy = original.clone()\n",
    "copy[0] = 888\n",
    "print(f\"\\nAfter cloning and modifying copy[0] = 888:\")\n",
    "print(f\"Original: {original}\")  # Unchanged!\n",
    "print(f\"Copy: {copy}\")\n",
    "\n",
    "print(\"\\nðŸ”‘ FAANG Interview Tip: Always use .clone() when you need to modify a tensor independently!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdsxzzss1o",
   "metadata": {},
   "source": [
    "### Contiguous Memory - Why `.contiguous()` Matters\n",
    "\n",
    "After certain operations (like transpose), the memory layout becomes non-contiguous.\n",
    "Some operations (like `.view()`) require contiguous memory.\n",
    "\n",
    "**Interview Question**: \"When would you need to call `.contiguous()`?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ybi49yk5hc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original is contiguous: True\n",
      "Original stride: (3, 1)\n",
      "\n",
      "Transposed is contiguous: False\n",
      "Transposed stride: (1, 3)\n",
      "\n",
      "âŒ Error: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "After .contiguous(): True\n",
      "Now we can view: tensor([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "âœ… reshape() handles it: tensor([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "ðŸ”‘ FAANG Tip: Use .reshape() over .view() for safer code. View is faster but reshape handles non-contiguous.\n"
     ]
    }
   ],
   "source": [
    "# Contiguous Memory Demo\n",
    "\n",
    "t = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(f\"Original is contiguous: {t.is_contiguous()}\")\n",
    "print(f\"Original stride: {t.stride()}\")\n",
    "\n",
    "# Transpose creates a non-contiguous view\n",
    "t_transposed = t.t()\n",
    "print(f\"\\nTransposed is contiguous: {t_transposed.is_contiguous()}\")\n",
    "print(f\"Transposed stride: {t_transposed.stride()}\")\n",
    "\n",
    "# This will fail:\n",
    "try:\n",
    "    t_transposed.view(6)  # Can't view non-contiguous tensor!\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "\n",
    "# Solution: Make it contiguous first\n",
    "t_contiguous = t_transposed.contiguous()\n",
    "print(f\"\\nAfter .contiguous(): {t_contiguous.is_contiguous()}\")\n",
    "print(f\"Now we can view: {t_contiguous.view(6)}\")\n",
    "\n",
    "# BETTER: Use .reshape() instead - it handles this automatically!\n",
    "print(f\"\\nâœ… reshape() handles it: {t_transposed.reshape(6)}\")\n",
    "\n",
    "print(\"\\nðŸ”‘ FAANG Tip: Use .reshape() over .view() for safer code. View is faster but reshape handles non-contiguous.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vb3xbn3k009",
   "metadata": {},
   "source": [
    "### In-Place Operations - Memory Efficiency at Scale\n",
    "\n",
    "In-place operations modify tensors directly without creating copies.\n",
    "Denoted by underscore suffix: `add_()`, `mul_()`, `zero_()`, etc.\n",
    "\n",
    "**Trade-offs**:\n",
    "- âœ… Saves memory (critical for large models)\n",
    "- âŒ Can break autograd computation graphs\n",
    "- âŒ Harder to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "xd4lexlh78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x: tensor([1., 2., 3.]), id: 5000013344\n",
      "After x + 10: y = tensor([11., 12., 13.]), x = tensor([1., 2., 3.])\n",
      "Same object? False\n",
      "\n",
      "After x.add_(10): x = tensor([11., 12., 13.])\n",
      "After mul_(2): tensor([2., 4., 6.])\n",
      "After zero_(): tensor([0., 0., 0.])\n",
      "After fill_(42): tensor([42., 42., 42.])\n",
      "\n",
      "âŒ In-place error with gradients: a leaf Variable that requires grad is being used in an in-place operation....\n",
      "\n",
      "ðŸ”‘ FAANG Tip: Avoid in-place ops during forward pass. Use them for weight updates or inference only.\n"
     ]
    }
   ],
   "source": [
    "# In-Place Operations Demo\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(f\"Original x: {x}, id: {id(x)}\")\n",
    "\n",
    "# Out-of-place (creates new tensor)\n",
    "y = x + 10\n",
    "print(f\"After x + 10: y = {y}, x = {x}\")\n",
    "print(f\"Same object? {id(x) == id(y)}\")  # False\n",
    "\n",
    "# In-place (modifies x directly)\n",
    "x.add_(10)\n",
    "print(f\"\\nAfter x.add_(10): x = {x}\")\n",
    "\n",
    "# Common in-place operations\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x.mul_(2)      # x = x * 2\n",
    "print(f\"After mul_(2): {x}\")\n",
    "\n",
    "x.zero_()      # x = 0\n",
    "print(f\"After zero_(): {x}\")\n",
    "\n",
    "x.fill_(42)    # x = 42\n",
    "print(f\"After fill_(42): {x}\")\n",
    "\n",
    "# DANGER: In-place on tensors with requires_grad can cause issues!\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * 2\n",
    "try:\n",
    "    x.add_(1)  # This breaks the computation graph!\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nâŒ In-place error with gradients: {str(e)[:80]}...\")\n",
    "\n",
    "print(\"\\nðŸ”‘ FAANG Tip: Avoid in-place ops during forward pass. Use them for weight updates or inference only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01w0d84wqz1d",
   "metadata": {},
   "source": [
    "## Part 7: Tensor Creation Patterns (Production Code)\n",
    "\n",
    "Different creation methods for different scenarios. Knowing these shows production experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "o0gnjn8i02m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation patterns demo:\n",
      "zeros_like matches device: True\n",
      "linspace: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "eye:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "\n",
      "ðŸ”‘ FAANG Tip: Always use *_like() methods in multi-GPU code to ensure device consistency!\n"
     ]
    }
   ],
   "source": [
    "# Production Tensor Creation Patterns\n",
    "\n",
    "# 1. Zeros/Ones - For initializing buffers\n",
    "zeros = torch.zeros(3, 4)                    # All zeros\n",
    "ones = torch.ones(3, 4)                      # All ones\n",
    "full = torch.full((3, 4), fill_value=3.14)   # All same value\n",
    "\n",
    "# 2. Like methods - Match device/dtype of existing tensor (CRITICAL for multi-GPU)\n",
    "x = torch.randn(2, 3, device='cpu', dtype=torch.float32)\n",
    "zeros_like = torch.zeros_like(x)  # Same device, dtype, shape!\n",
    "ones_like = torch.ones_like(x)\n",
    "\n",
    "# 3. Random initialization\n",
    "uniform = torch.rand(3, 4)          # Uniform [0, 1)\n",
    "normal = torch.randn(3, 4)          # Normal (mean=0, std=1)\n",
    "randint = torch.randint(0, 10, (3, 4))  # Random integers\n",
    "\n",
    "# 4. Ranges\n",
    "arange = torch.arange(0, 10, 2)     # [0, 2, 4, 6, 8]\n",
    "linspace = torch.linspace(0, 1, 5)  # [0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "# 5. Identity matrix (for attention masks, etc.)\n",
    "eye = torch.eye(4)\n",
    "\n",
    "# 6. Diagonal matrix\n",
    "diag = torch.diag(torch.tensor([1, 2, 3]))\n",
    "\n",
    "# 7. Empty (FAST but DANGEROUS - contains garbage!)\n",
    "empty = torch.empty(3, 4)  # Faster than zeros, but uninitialized\n",
    "\n",
    "print(\"Creation patterns demo:\")\n",
    "print(f\"zeros_like matches device: {zeros_like.device == x.device}\")\n",
    "print(f\"linspace: {linspace}\")\n",
    "print(f\"eye:\\n{eye}\")\n",
    "\n",
    "print(\"\\nðŸ”‘ FAANG Tip: Always use *_like() methods in multi-GPU code to ensure device consistency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "op7y8hq91e",
   "metadata": {},
   "source": [
    "## Part 8: Common Tensor Operations (Interview Favorites)\n",
    "\n",
    "These operations appear in almost every ML codebase and interview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "k0f4fo384ql",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dimension Operations ===\n",
      "Sum all: 21.0\n",
      "Sum along dim 0 (columns): tensor([5., 7., 9.])\n",
      "Sum along dim 1 (rows): tensor([ 6., 15.])\n",
      "Mean: 3.5\n",
      "Max: 6.0, Argmax: 5\n",
      "\n",
      "=== Squeeze/Unsqueeze ===\n",
      "Original shape: torch.Size([3])\n",
      "After unsqueeze(0): torch.Size([1, 3])\n",
      "After unsqueeze(1): torch.Size([3, 1])\n",
      "\n",
      "Before squeeze: torch.Size([1, 3, 1])\n",
      "After squeeze(): torch.Size([3])\n",
      "After squeeze(0): torch.Size([3, 1])\n",
      "\n",
      "=== Cat vs Stack ===\n",
      "cat dim=0 shape: torch.Size([4, 2])\n",
      "stack dim=0 shape: torch.Size([2, 2, 2])\n",
      "\n",
      "=== Permute ===\n",
      "CHW: torch.Size([3, 224, 224]) -> HWC: torch.Size([224, 224, 3])\n",
      "\n",
      "=== Flatten ===\n",
      "Before flatten: torch.Size([2, 3, 4])\n",
      "flatten(): torch.Size([24])\n",
      "flatten(1): torch.Size([2, 12])\n",
      "\n",
      "ðŸ”‘ FAANG Tip: Know dim=0 vs dim=1 - 90% of shape bugs are dimension mismatches!\n"
     ]
    }
   ],
   "source": [
    "# Common Tensor Operations - Know These Cold!\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# === Dimension Operations ===\n",
    "print(\"=== Dimension Operations ===\")\n",
    "print(f\"Sum all: {x.sum()}\")\n",
    "print(f\"Sum along dim 0 (columns): {x.sum(dim=0)}\")  # [5, 7, 9]\n",
    "print(f\"Sum along dim 1 (rows): {x.sum(dim=1)}\")     # [6, 15]\n",
    "print(f\"Mean: {x.mean()}\")\n",
    "print(f\"Max: {x.max()}, Argmax: {x.argmax()}\")       # Value and index\n",
    "\n",
    "# === Squeeze/Unsqueeze (add/remove dimensions) ===\n",
    "print(\"\\n=== Squeeze/Unsqueeze ===\")\n",
    "y = torch.tensor([1, 2, 3])\n",
    "print(f\"Original shape: {y.shape}\")              # [3]\n",
    "y_unsqueezed = y.unsqueeze(0)                    # Add dim at position 0\n",
    "print(f\"After unsqueeze(0): {y_unsqueezed.shape}\")  # [1, 3]\n",
    "y_unsqueezed2 = y.unsqueeze(1)                   # Add dim at position 1\n",
    "print(f\"After unsqueeze(1): {y_unsqueezed2.shape}\") # [3, 1]\n",
    "\n",
    "z = torch.zeros(1, 3, 1)\n",
    "print(f\"\\nBefore squeeze: {z.shape}\")            # [1, 3, 1]\n",
    "print(f\"After squeeze(): {z.squeeze().shape}\")  # [3] - removes ALL size-1 dims\n",
    "print(f\"After squeeze(0): {z.squeeze(0).shape}\") # [3, 1] - removes only dim 0\n",
    "\n",
    "# === Concatenation vs Stacking ===\n",
    "print(\"\\n=== Cat vs Stack ===\")\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "cat_result = torch.cat([a, b], dim=0)  # Concatenate along existing dim\n",
    "print(f\"cat dim=0 shape: {cat_result.shape}\")  # [4, 2]\n",
    "\n",
    "stack_result = torch.stack([a, b], dim=0)  # Create NEW dimension\n",
    "print(f\"stack dim=0 shape: {stack_result.shape}\")  # [2, 2, 2]\n",
    "\n",
    "# === Permute (reorder dimensions) ===\n",
    "print(\"\\n=== Permute ===\")\n",
    "img = torch.randn(3, 224, 224)  # CHW format (PyTorch)\n",
    "img_hwc = img.permute(1, 2, 0)  # Convert to HWC (for matplotlib/PIL)\n",
    "print(f\"CHW: {img.shape} -> HWC: {img_hwc.shape}\")\n",
    "\n",
    "# === Flatten ===\n",
    "print(\"\\n=== Flatten ===\")\n",
    "x = torch.randn(2, 3, 4)\n",
    "print(f\"Before flatten: {x.shape}\")\n",
    "print(f\"flatten(): {x.flatten().shape}\")           # [24]\n",
    "print(f\"flatten(1): {x.flatten(1).shape}\")         # [2, 12] - keep batch dim\n",
    "\n",
    "print(\"\\nðŸ”‘ FAANG Tip: Know dim=0 vs dim=1 - 90% of shape bugs are dimension mismatches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bhv4u5usenu",
   "metadata": {},
   "source": [
    "## Part 9: FAANG Interview Questions - Tensors & Memory\n",
    "\n",
    "### Question 1: \"Explain the difference between .view() and .reshape()\"\n",
    "\n",
    "**Answer**:\n",
    "- `.view()` returns a view (shared memory) but REQUIRES contiguous memory\n",
    "- `.reshape()` returns a view when possible, but copies if not contiguous\n",
    "- `.view()` is slightly faster but less safe\n",
    "- Use `.reshape()` in production for robustness\n",
    "\n",
    "### Question 2: \"What are strides in PyTorch? Why do they matter?\"\n",
    "\n",
    "**Answer**:\n",
    "Strides define how many elements to skip in memory to move one step in each dimension.\n",
    "- Enables zero-copy transpose, reshape, and slicing\n",
    "- Non-contiguous tensors have different stride patterns\n",
    "- Critical for understanding memory layout optimization\n",
    "\n",
    "### Question 3: \"How would you efficiently handle a batch of images on GPU?\"\n",
    "\n",
    "**Answer**:\n",
    "```python\n",
    "# 1. Create tensor directly on GPU\n",
    "images = torch.randn(32, 3, 224, 224, device='cuda')\n",
    "\n",
    "# 2. Or transfer with non-blocking (overlap CPU/GPU work)\n",
    "images = images.to('cuda', non_blocking=True)\n",
    "\n",
    "# 3. Use pinned memory for faster CPU->GPU transfer\n",
    "images = torch.randn(32, 3, 224, 224).pin_memory()\n",
    "images_gpu = images.to('cuda', non_blocking=True)\n",
    "```\n",
    "\n",
    "### Question 4: \"What's the difference between torch.tensor() and torch.Tensor()?\"\n",
    "\n",
    "**Answer**:\n",
    "- `torch.tensor()` - ALWAYS creates a new copy, infers dtype from data\n",
    "- `torch.Tensor()` - May share memory, always creates float32\n",
    "- Best practice: Always use `torch.tensor()` for explicit, predictable behavior\n",
    "\n",
    "### Question 5: \"How do you debug shape mismatches?\"\n",
    "\n",
    "**Answer**:\n",
    "```python\n",
    "# 1. Print shapes at each step\n",
    "print(f\"After conv: {x.shape}\")\n",
    "\n",
    "# 2. Use named tensors (PyTorch 1.4+)\n",
    "x = x.refine_names('batch', 'channel', 'height', 'width')\n",
    "\n",
    "# 3. Use einops for clarity\n",
    "from einops import rearrange\n",
    "x = rearrange(x, 'b c h w -> b (c h w)')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uy97464de1i",
   "metadata": {},
   "source": [
    "## Summary: Tensor Mastery Checklist\n",
    "\n",
    "### Foundation (Know These Cold)\n",
    "- [ ] Tensor = N-dimensional array (Scalar, Vector, Matrix, ND Tensor)\n",
    "- [ ] GPU vs CPU: `.to(device)`, `.cuda()`, `.cpu()`\n",
    "- [ ] Data types: `float32` (default), `float16` (mixed precision), `int64` (indices)\n",
    "- [ ] Broadcasting: automatic shape expansion for element-wise ops\n",
    "\n",
    "### Memory (Interview Favorites)\n",
    "- [ ] Views vs Copies: `.view()` shares memory, `.clone()` copies\n",
    "- [ ] Contiguous: `.is_contiguous()`, `.contiguous()`, stride patterns\n",
    "- [ ] In-place: underscore suffix (`add_()`, `mul_()`) - use carefully with autograd\n",
    "\n",
    "### Operations (Daily Usage)\n",
    "- [ ] Reshape: `.view()`, `.reshape()`, `.flatten()`, `.squeeze()`, `.unsqueeze()`\n",
    "- [ ] Combine: `torch.cat()` (along dim), `torch.stack()` (new dim)\n",
    "- [ ] Reduce: `.sum()`, `.mean()`, `.max()` with `dim` argument\n",
    "- [ ] Permute: `.permute()`, `.transpose()` for dimension reordering\n",
    "\n",
    "### Production Patterns\n",
    "- [ ] Use `*_like()` for device/dtype consistency\n",
    "- [ ] Pin memory for fast CPU->GPU transfer\n",
    "- [ ] Prefer `.reshape()` over `.view()` for safety\n",
    "- [ ] Use `torch.no_grad()` for inference (we'll cover this next)\n",
    "\n",
    "---\n",
    "**Next**: Notebook 01 - Autograd and Gradients (How PyTorch computes derivatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
