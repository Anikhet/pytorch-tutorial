{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12d7ac8",
   "metadata": {},
   "source": [
    "# PyTorch Deep Dive: Introduction and Tensors\n",
    "\n",
    "Welcome to the absolute foundation of Deep Learning. \n",
    "\n",
    "Before we write code, we need to define the **Objects** we are working with.\n",
    "\n",
    "## Learning Objectives\n",
    "- **The Vocabulary**: What is a \"Tensor\", \"Scalar\", \"Vector\", and \"Matrix\"?\n",
    "- **The Intuition**: Tensors as \"Excel Sheets on Steroids\".\n",
    "- **The Hardware**: CPU vs GPU (Minivan vs Sports Car).\n",
    "- **The Mechanics**: Shapes, Dtypes, and Broadcasting.\n",
    "- **The Deep Dive**: Strides and Memory Layout (What actually happens in RAM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d922660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84392d28",
   "metadata": {},
   "source": [
    "## Part 1: The Vocabulary (Definitions First)\n",
    "\n",
    "In Data Science, we have specific names for containers of numbers based on their dimensions.\n",
    "\n",
    "### 1. Scalar (0D)\n",
    "- A single number.\n",
    "- Example: `7`, `3.14`.\n",
    "- Use case: A loss value, a learning rate.\n",
    "\n",
    "### 2. Vector (1D)\n",
    "- A list of numbers.\n",
    "- Example: `[1, 2, 3]`.\n",
    "- Use case: A row of data, a bias term.\n",
    "\n",
    "### 3. Matrix (2D)\n",
    "- A grid of numbers (Rows and Columns).\n",
    "- Example: An Excel sheet, a black-and-white image.\n",
    "- Use case: A dataset, weights of a linear layer.\n",
    "\n",
    "### 4. Tensor (ND)\n",
    "- A generic term for N-dimensional arrays (3D, 4D, etc.).\n",
    "- Example: A color image (Height x Width x 3 Channels), a video (Time x H x W x C).\n",
    "- Use case: Complex data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233bafd",
   "metadata": {},
   "source": [
    "## Part 2: The Intuition (Excel on Steroids)\n",
    "\n",
    "Now that we know the terms, let's visualize them.\n",
    "\n",
    "- **2D Tensor**: Imagine a single Excel sheet.\n",
    "- **3D Tensor**: Imagine a **Workbook** containing multiple Excel sheets.\n",
    "- **4D Tensor**: Imagine a **Filing Cabinet** containing multiple Workbooks.\n",
    "- **5D Tensor**: Imagine a **Library** containing multiple Filing Cabinets.\n",
    "\n",
    "PyTorch Tensors are just these containers, but optimized for math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a8ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 7 (Shape: torch.Size([]))\n",
      "Vector: tensor([7, 2, 5]) (Shape: torch.Size([3]))\n",
      "Matrix:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) (Shape: torch.Size([2, 2]))\n",
      "3D Tensor Shape: torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensor (Scalar)\n",
    "scalar = torch.tensor(7)\n",
    "print(f\"Scalar: {scalar.item()} (Shape: {scalar.shape})\")\n",
    "\n",
    "# 1D Tensor (Vector)\n",
    "vector = torch.tensor([7, 2, 5])\n",
    "print(f\"Vector: {vector} (Shape: {vector.shape})\")\n",
    "\n",
    "# 2D Tensor (Matrix)\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"Matrix:\\n{matrix} (Shape: {matrix.shape})\")\n",
    "\n",
    "# 3D Tensor (Image-like)\n",
    "tensor3d = torch.rand(3, 4, 4) # 3 Channels, 4x4 pixels\n",
    "print(f\"3D Tensor Shape: {tensor3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c8263",
   "metadata": {},
   "source": [
    "## Part 3: The Hardware (Minivan vs Sports Car)\n",
    "\n",
    "Why do we use PyTorch Tensors instead of Python lists or NumPy arrays?\n",
    "\n",
    "**The GPU.**\n",
    "\n",
    "- **CPU (Central Processing Unit)**: Like a **Minivan**. It can carry a few things (instructions) very quickly and flexibly. Good for sequential logic.\n",
    "- **GPU (Graphics Processing Unit)**: Like a **Train** or **Fleet of Sports Cars**. It can carry MASSIVE amounts of data at once, but it's hard to turn. Good for parallel math (matrix multiplication).\n",
    "\n",
    "PyTorch Tensors can live on the GPU. NumPy arrays cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387cff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "x is on: cpu\n",
      "x_gpu is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Move tensor to GPU\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_gpu = x.to(device)\n",
    "\n",
    "print(f\"x is on: {x.device}\")\n",
    "print(f\"x_gpu is on: {x_gpu.device}\")\n",
    "\n",
    "# Note: You cannot add a CPU tensor to a GPU tensor. They live in different worlds!\n",
    "# x + x_gpu # This would error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84446d6c",
   "metadata": {},
   "source": [
    "## Part 4: The Mechanics (Broadcasting)\n",
    "\n",
    "Broadcasting is magic. It allows you to do math on tensors of different shapes.\n",
    "\n",
    "Imagine you have a matrix of students' scores (Rows=Students, Cols=Subjects).\n",
    "You want to add 5 bonus points to **every** score.\n",
    "\n",
    "You don't need to create a matrix of 5s. You just add `5`.\n",
    "PyTorch \"broadcasts\" (stretches) the `5` to match the matrix shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1654a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix + 5:\n",
      " tensor([[15, 25, 35],\n",
      "        [45, 55, 65]])\n",
      "Matrix + Vector:\n",
      " tensor([[11, 22, 33],\n",
      "        [41, 52, 63]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[10, 20, 30], \n",
    "                       [40, 50, 60]])\n",
    "\n",
    "# Add scalar (Broadcasting 5 to match 2x3)\n",
    "print(\"Matrix + 5:\\n\", matrix + 5)\n",
    "\n",
    "# Add vector (Broadcasting [1, 2, 3] to every row)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(\"Matrix + Vector:\\n\", matrix + vector)\n",
    "\n",
    "# Visualizing what happened:\n",
    "# [10, 20, 30] + [1, 2, 3] = [11, 22, 33]\n",
    "# [40, 50, 60] + [1, 2, 3] = [41, 52, 63]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7610967",
   "metadata": {},
   "source": [
    "## Part 5: The Deep Dive (Strides & Memory)\n",
    "\n",
    "Here is the secret: **A Tensor is just a 1D array in memory.**\n",
    "\n",
    "The \"shape\" (rows, columns) is an illusion created by **Strides**.\n",
    "\n",
    "- **Stride**: How many steps in memory do I need to jump to get to the next element in this dimension?\n",
    "\n",
    "Example: Matrix 2x3\n",
    "`[[1, 2, 3], [4, 5, 6]]`\n",
    "\n",
    "In memory (RAM): `[1, 2, 3, 4, 5, 6]`\n",
    "\n",
    "To go from `1` to `2` (next column), jump 1 step.\n",
    "To go from `1` to `4` (next row), jump 3 steps.\n",
    "\n",
    "Stride = `(3, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3])\n",
      "Stride: (3, 1)\n",
      "\n",
      "Transposed Shape: torch.Size([3, 2])\n",
      "Transposed Stride: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(f\"Shape: {t.shape}\")\n",
    "print(f\"Stride: {t.stride()}\")\n",
    "\n",
    "# Transpose it (swap rows/cols)\n",
    "t_T = t.t()\n",
    "print(f\"\\nTransposed Shape: {t_T.shape}\")\n",
    "print(f\"Transposed Stride: {t_T.stride()}\")\n",
    "\n",
    "# Notice: The DATA in memory didn't move! PyTorch just swapped the strides.\n",
    "# This makes transposing instant, even for huge matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 6: Advanced Tensor Operations (FAANG Interview Essentials)\n\n### Views vs Copies - Critical Interview Topic\n\n**View**: A new tensor object that shares the same underlying data.\n**Copy**: A completely independent tensor with its own memory.\n\nThis distinction is CRITICAL for:\n1. Memory efficiency (views are nearly free)\n2. Bug prevention (modifying views affects originals)\n3. Understanding when `contiguous()` is needed"
  },
  {
   "cell_type": "code",
   "id": "euw3t11ooll",
   "source": "# Views vs Copies - FAANG Interview Classic\n\noriginal = torch.tensor([1, 2, 3, 4, 5, 6])\n\n# View: shares memory with original\nview = original.view(2, 3)\nprint(f\"Original: {original}\")\nprint(f\"View:\\n{view}\")\nprint(f\"Same memory? {original.data_ptr() == view.data_ptr()}\")  # True!\n\n# Modify the view - affects original!\nview[0, 0] = 999\nprint(f\"\\nAfter modifying view[0,0] = 999:\")\nprint(f\"Original: {original}\")  # Also changed!\nprint(f\"View:\\n{view}\")\n\n# Clone: creates independent copy\noriginal = torch.tensor([1, 2, 3, 4, 5, 6])\ncopy = original.clone()\ncopy[0] = 888\nprint(f\"\\nAfter cloning and modifying copy[0] = 888:\")\nprint(f\"Original: {original}\")  # Unchanged!\nprint(f\"Copy: {copy}\")\n\nprint(\"\\nðŸ”‘ FAANG Interview Tip: Always use .clone() when you need to modify a tensor independently!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bdsxzzss1o",
   "source": "### Contiguous Memory - Why `.contiguous()` Matters\n\nAfter certain operations (like transpose), the memory layout becomes non-contiguous.\nSome operations (like `.view()`) require contiguous memory.\n\n**Interview Question**: \"When would you need to call `.contiguous()`?\"",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ybi49yk5hc",
   "source": "# Contiguous Memory Demo\n\nt = torch.tensor([[1, 2, 3],\n                  [4, 5, 6]])\n\nprint(f\"Original is contiguous: {t.is_contiguous()}\")\nprint(f\"Original stride: {t.stride()}\")\n\n# Transpose creates a non-contiguous view\nt_transposed = t.t()\nprint(f\"\\nTransposed is contiguous: {t_transposed.is_contiguous()}\")\nprint(f\"Transposed stride: {t_transposed.stride()}\")\n\n# This will fail:\ntry:\n    t_transposed.view(6)  # Can't view non-contiguous tensor!\nexcept RuntimeError as e:\n    print(f\"\\nâŒ Error: {e}\")\n\n# Solution: Make it contiguous first\nt_contiguous = t_transposed.contiguous()\nprint(f\"\\nAfter .contiguous(): {t_contiguous.is_contiguous()}\")\nprint(f\"Now we can view: {t_contiguous.view(6)}\")\n\n# BETTER: Use .reshape() instead - it handles this automatically!\nprint(f\"\\nâœ… reshape() handles it: {t_transposed.reshape(6)}\")\n\nprint(\"\\nðŸ”‘ FAANG Tip: Use .reshape() over .view() for safer code. View is faster but reshape handles non-contiguous.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vb3xbn3k009",
   "source": "### In-Place Operations - Memory Efficiency at Scale\n\nIn-place operations modify tensors directly without creating copies.\nDenoted by underscore suffix: `add_()`, `mul_()`, `zero_()`, etc.\n\n**Trade-offs**:\n- âœ… Saves memory (critical for large models)\n- âŒ Can break autograd computation graphs\n- âŒ Harder to debug",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xd4lexlh78a",
   "source": "# In-Place Operations Demo\n\nx = torch.tensor([1.0, 2.0, 3.0])\nprint(f\"Original x: {x}, id: {id(x)}\")\n\n# Out-of-place (creates new tensor)\ny = x + 10\nprint(f\"After x + 10: y = {y}, x = {x}\")\nprint(f\"Same object? {id(x) == id(y)}\")  # False\n\n# In-place (modifies x directly)\nx.add_(10)\nprint(f\"\\nAfter x.add_(10): x = {x}\")\n\n# Common in-place operations\nx = torch.tensor([1.0, 2.0, 3.0])\nx.mul_(2)      # x = x * 2\nprint(f\"After mul_(2): {x}\")\n\nx.zero_()      # x = 0\nprint(f\"After zero_(): {x}\")\n\nx.fill_(42)    # x = 42\nprint(f\"After fill_(42): {x}\")\n\n# DANGER: In-place on tensors with requires_grad can cause issues!\nx = torch.tensor([1.0, 2.0], requires_grad=True)\ny = x * 2\ntry:\n    x.add_(1)  # This breaks the computation graph!\nexcept RuntimeError as e:\n    print(f\"\\nâŒ In-place error with gradients: {str(e)[:80]}...\")\n\nprint(\"\\nðŸ”‘ FAANG Tip: Avoid in-place ops during forward pass. Use them for weight updates or inference only.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "01w0d84wqz1d",
   "source": "## Part 7: Tensor Creation Patterns (Production Code)\n\nDifferent creation methods for different scenarios. Knowing these shows production experience.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "o0gnjn8i02m",
   "source": "# Production Tensor Creation Patterns\n\n# 1. Zeros/Ones - For initializing buffers\nzeros = torch.zeros(3, 4)                    # All zeros\nones = torch.ones(3, 4)                      # All ones\nfull = torch.full((3, 4), fill_value=3.14)   # All same value\n\n# 2. Like methods - Match device/dtype of existing tensor (CRITICAL for multi-GPU)\nx = torch.randn(2, 3, device='cpu', dtype=torch.float32)\nzeros_like = torch.zeros_like(x)  # Same device, dtype, shape!\nones_like = torch.ones_like(x)\n\n# 3. Random initialization\nuniform = torch.rand(3, 4)          # Uniform [0, 1)\nnormal = torch.randn(3, 4)          # Normal (mean=0, std=1)\nrandint = torch.randint(0, 10, (3, 4))  # Random integers\n\n# 4. Ranges\narange = torch.arange(0, 10, 2)     # [0, 2, 4, 6, 8]\nlinspace = torch.linspace(0, 1, 5)  # [0, 0.25, 0.5, 0.75, 1.0]\n\n# 5. Identity matrix (for attention masks, etc.)\neye = torch.eye(4)\n\n# 6. Diagonal matrix\ndiag = torch.diag(torch.tensor([1, 2, 3]))\n\n# 7. Empty (FAST but DANGEROUS - contains garbage!)\nempty = torch.empty(3, 4)  # Faster than zeros, but uninitialized\n\nprint(\"Creation patterns demo:\")\nprint(f\"zeros_like matches device: {zeros_like.device == x.device}\")\nprint(f\"linspace: {linspace}\")\nprint(f\"eye:\\n{eye}\")\n\nprint(\"\\nðŸ”‘ FAANG Tip: Always use *_like() methods in multi-GPU code to ensure device consistency!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "op7y8hq91e",
   "source": "## Part 8: Common Tensor Operations (Interview Favorites)\n\nThese operations appear in almost every ML codebase and interview.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "k0f4fo384ql",
   "source": "# Common Tensor Operations - Know These Cold!\n\nx = torch.tensor([[1, 2, 3],\n                  [4, 5, 6]], dtype=torch.float32)\n\n# === Dimension Operations ===\nprint(\"=== Dimension Operations ===\")\nprint(f\"Sum all: {x.sum()}\")\nprint(f\"Sum along dim 0 (columns): {x.sum(dim=0)}\")  # [5, 7, 9]\nprint(f\"Sum along dim 1 (rows): {x.sum(dim=1)}\")     # [6, 15]\nprint(f\"Mean: {x.mean()}\")\nprint(f\"Max: {x.max()}, Argmax: {x.argmax()}\")       # Value and index\n\n# === Squeeze/Unsqueeze (add/remove dimensions) ===\nprint(\"\\n=== Squeeze/Unsqueeze ===\")\ny = torch.tensor([1, 2, 3])\nprint(f\"Original shape: {y.shape}\")              # [3]\ny_unsqueezed = y.unsqueeze(0)                    # Add dim at position 0\nprint(f\"After unsqueeze(0): {y_unsqueezed.shape}\")  # [1, 3]\ny_unsqueezed2 = y.unsqueeze(1)                   # Add dim at position 1\nprint(f\"After unsqueeze(1): {y_unsqueezed2.shape}\") # [3, 1]\n\nz = torch.zeros(1, 3, 1)\nprint(f\"\\nBefore squeeze: {z.shape}\")            # [1, 3, 1]\nprint(f\"After squeeze(): {z.squeeze().shape}\")  # [3] - removes ALL size-1 dims\nprint(f\"After squeeze(0): {z.squeeze(0).shape}\") # [3, 1] - removes only dim 0\n\n# === Concatenation vs Stacking ===\nprint(\"\\n=== Cat vs Stack ===\")\na = torch.tensor([[1, 2], [3, 4]])\nb = torch.tensor([[5, 6], [7, 8]])\n\ncat_result = torch.cat([a, b], dim=0)  # Concatenate along existing dim\nprint(f\"cat dim=0 shape: {cat_result.shape}\")  # [4, 2]\n\nstack_result = torch.stack([a, b], dim=0)  # Create NEW dimension\nprint(f\"stack dim=0 shape: {stack_result.shape}\")  # [2, 2, 2]\n\n# === Permute (reorder dimensions) ===\nprint(\"\\n=== Permute ===\")\nimg = torch.randn(3, 224, 224)  # CHW format (PyTorch)\nimg_hwc = img.permute(1, 2, 0)  # Convert to HWC (for matplotlib/PIL)\nprint(f\"CHW: {img.shape} -> HWC: {img_hwc.shape}\")\n\n# === Flatten ===\nprint(\"\\n=== Flatten ===\")\nx = torch.randn(2, 3, 4)\nprint(f\"Before flatten: {x.shape}\")\nprint(f\"flatten(): {x.flatten().shape}\")           # [24]\nprint(f\"flatten(1): {x.flatten(1).shape}\")         # [2, 12] - keep batch dim\n\nprint(\"\\nðŸ”‘ FAANG Tip: Know dim=0 vs dim=1 - 90% of shape bugs are dimension mismatches!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bhv4u5usenu",
   "source": "## Part 9: FAANG Interview Questions - Tensors & Memory\n\n### Question 1: \"Explain the difference between .view() and .reshape()\"\n\n**Answer**:\n- `.view()` returns a view (shared memory) but REQUIRES contiguous memory\n- `.reshape()` returns a view when possible, but copies if not contiguous\n- `.view()` is slightly faster but less safe\n- Use `.reshape()` in production for robustness\n\n### Question 2: \"What are strides in PyTorch? Why do they matter?\"\n\n**Answer**:\nStrides define how many elements to skip in memory to move one step in each dimension.\n- Enables zero-copy transpose, reshape, and slicing\n- Non-contiguous tensors have different stride patterns\n- Critical for understanding memory layout optimization\n\n### Question 3: \"How would you efficiently handle a batch of images on GPU?\"\n\n**Answer**:\n```python\n# 1. Create tensor directly on GPU\nimages = torch.randn(32, 3, 224, 224, device='cuda')\n\n# 2. Or transfer with non-blocking (overlap CPU/GPU work)\nimages = images.to('cuda', non_blocking=True)\n\n# 3. Use pinned memory for faster CPU->GPU transfer\nimages = torch.randn(32, 3, 224, 224).pin_memory()\nimages_gpu = images.to('cuda', non_blocking=True)\n```\n\n### Question 4: \"What's the difference between torch.tensor() and torch.Tensor()?\"\n\n**Answer**:\n- `torch.tensor()` - ALWAYS creates a new copy, infers dtype from data\n- `torch.Tensor()` - May share memory, always creates float32\n- Best practice: Always use `torch.tensor()` for explicit, predictable behavior\n\n### Question 5: \"How do you debug shape mismatches?\"\n\n**Answer**:\n```python\n# 1. Print shapes at each step\nprint(f\"After conv: {x.shape}\")\n\n# 2. Use named tensors (PyTorch 1.4+)\nx = x.refine_names('batch', 'channel', 'height', 'width')\n\n# 3. Use einops for clarity\nfrom einops import rearrange\nx = rearrange(x, 'b c h w -> b (c h w)')\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "uy97464de1i",
   "source": "## Summary: Tensor Mastery Checklist\n\n### Foundation (Know These Cold)\n- [ ] Tensor = N-dimensional array (Scalar, Vector, Matrix, ND Tensor)\n- [ ] GPU vs CPU: `.to(device)`, `.cuda()`, `.cpu()`\n- [ ] Data types: `float32` (default), `float16` (mixed precision), `int64` (indices)\n- [ ] Broadcasting: automatic shape expansion for element-wise ops\n\n### Memory (Interview Favorites)\n- [ ] Views vs Copies: `.view()` shares memory, `.clone()` copies\n- [ ] Contiguous: `.is_contiguous()`, `.contiguous()`, stride patterns\n- [ ] In-place: underscore suffix (`add_()`, `mul_()`) - use carefully with autograd\n\n### Operations (Daily Usage)\n- [ ] Reshape: `.view()`, `.reshape()`, `.flatten()`, `.squeeze()`, `.unsqueeze()`\n- [ ] Combine: `torch.cat()` (along dim), `torch.stack()` (new dim)\n- [ ] Reduce: `.sum()`, `.mean()`, `.max()` with `dim` argument\n- [ ] Permute: `.permute()`, `.transpose()` for dimension reordering\n\n### Production Patterns\n- [ ] Use `*_like()` for device/dtype consistency\n- [ ] Pin memory for fast CPU->GPU transfer\n- [ ] Prefer `.reshape()` over `.view()` for safety\n- [ ] Use `torch.no_grad()` for inference (we'll cover this next)\n\n---\n**Next**: Notebook 01 - Autograd and Gradients (How PyTorch computes derivatives)",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}