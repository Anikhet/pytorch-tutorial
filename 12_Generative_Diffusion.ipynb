{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Generative Diffusion Models\n",
    "\n",
    "Diffusion models (like Stable Diffusion and DALL-E) generate images by learning to reverse a gradual noise process. They start with pure noise and slowly refine it into an image.\n",
    "\n",
    "In this notebook, we will implement the core mathematics of **DDPM (Denoising Diffusion Probabilistic Models)**.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the Forward Diffusion Process (Adding Noise)\n",
    "- Understand the Reverse Diffusion Process (Denoising)\n",
    "- Implement the Noise Schedule\n",
    "- Build a simplified U-Net for noise prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Forward Process (Adding Noise)\n",
    "\n",
    "We take an image $x_0$ and add Gaussian noise over $T$ steps until it becomes pure noise $x_T$.\n",
    "\n",
    "Formula:\n",
    "$$ q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t I) $$\n",
    "\n",
    "We can jump directly to any step $t$:\n",
    "$$ x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon $$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, I)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Define schedule\n",
    "T = 200\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \"\"\"Helper to get value at index t and reshape to match x\"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
    "    \"\"\"Takes an image and a timestep t and returns the noisy image at t\"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(torch.sqrt(alphas_cumprod), t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(torch.sqrt(1. - alphas_cumprod), t, x_0.shape)\n",
    "    \n",
    "    # Mean + Variance\n",
    "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise\n",
    "\n",
    "# Visualize\n",
    "image = torch.zeros((1, 3, 64, 64)) # Dummy black image\n",
    "image[:, :, 16:48, 16:48] = 1.0 # White square in middle\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "for idx, t_val in enumerate([0, 50, 100, 199]):\n",
    "    t = torch.tensor([t_val])\n",
    "    noisy_image, _ = forward_diffusion_sample(image, t)\n",
    "    \n",
    "    plt.subplot(1, 4, idx+1)\n",
    "    plt.imshow(noisy_image[0].permute(1, 2, 0).clamp(0, 1))\n",
    "    plt.title(f\"t={t_val}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Reverse Process (The Model)\n",
    "\n",
    "We need a neural network that takes a noisy image $x_t$ and the timestep $t$, and predicts the noise $\\epsilon$ that was added.\n",
    "\n",
    "We typically use a **U-Net**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"A very simplified U-Net for demonstration\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Downsample\n",
    "        self.down1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.down2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        # Time embedding (simplified)\n",
    "        self.time_mlp = nn.Linear(1, 128)\n",
    "        \n",
    "        # Upsample\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 3, padding=1)\n",
    "        self.up2 = nn.ConvTranspose2d(64, 3, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Embed time\n",
    "        t = t.float().view(-1, 1)\n",
    "        t_emb = self.time_mlp(t).view(-1, 128, 1, 1)\n",
    "        \n",
    "        # Down\n",
    "        x1 = F.relu(self.down1(x))\n",
    "        x2 = F.relu(self.down2(x1))\n",
    "        \n",
    "        # Add time info\n",
    "        x2 = x2 + t_emb\n",
    "        \n",
    "        # Up\n",
    "        x = F.relu(self.up1(x2))\n",
    "        x = self.up2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleUNet()\n",
    "print(\"Model created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop\n",
    "\n",
    "1. Sample a random image $x_0$.\n",
    "2. Sample a random timestep $t$.\n",
    "3. Add noise to get $x_t$.\n",
    "4. Model predicts the noise: $\\hat{\\epsilon} = \\text{Model}(x_t, t)$.\n",
    "5. Loss is MSE between real noise $\\epsilon$ and predicted noise $\\hat{\\epsilon}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Training Step\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 1. Get data\n",
    "x_0 = torch.randn(4, 3, 64, 64) # Batch of 4 images\n",
    "t = torch.randint(0, T, (4,))\n",
    "\n",
    "# 2. Forward diffusion\n",
    "x_t, noise = forward_diffusion_sample(x_0, t)\n",
    "\n",
    "# 3. Predict noise\n",
    "noise_pred = model(x_t, t)\n",
    "\n",
    "# 4. Loss\n",
    "loss = F.mse_loss(noise, noise_pred)\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sampling (Generation)\n",
    "\n",
    "To generate an image:\n",
    "1. Start with pure noise $x_T$.\n",
    "2. Loop backwards from $T$ to $0$.\n",
    "3. At each step, remove a bit of noise using the model's prediction.\n",
    "\n",
    "*(Code omitted for brevity, but involves subtracting the predicted noise and adding a small amount of random noise back for stability)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Diffusion**: A process of slowly destroying data with noise, then learning to reverse it.\n",
    "2. **Forward Process**: Fixed mathematical formula (no learning).\n",
    "3. **Reverse Process**: Learned by a U-Net.\n",
    "4. **Objective**: Predict the noise that was added."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
