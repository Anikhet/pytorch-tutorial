{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c3a12f",
   "metadata": {},
   "source": [
    "# PyTorch Deep Dive: Training Your First Model\n",
    "\n",
    "We have the Data (Tensor). We have the Machine (Model). We have the Math (Autograd).\n",
    "\n",
    "Now we need to teach the machine. This is **Training**.\n",
    "\n",
    "## Learning Objectives\n",
    "- **The Vocabulary**: What is an \"Epoch\", \"Batch\", \"Loss\", and \"Optimizer\"?\n",
    "- **The Intuition**: Training as \"Learning to Ride a Bike\".\n",
    "- **The Loop**: The 5-step process that repeats millions of times.\n",
    "- **The Visual**: Watching the loss go down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860aa163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06888d76",
   "metadata": {},
   "source": [
    "## Part 1: The Vocabulary (Definitions First)\n",
    "\n",
    "Training a model is like training an athlete. Here are the terms:\n",
    "\n",
    "### 1. Epoch\n",
    "- One full pass through the entire dataset.\n",
    "- Example: If you have 1000 images and you look at all 1000, that's 1 Epoch.\n",
    "- Analogy: Reading the textbook cover-to-cover once.\n",
    "\n",
    "### 2. Batch\n",
    "- A small chunk of data processed at once.\n",
    "- We don't learn from 1 example at a time (too slow/noisy), nor all at once (too big for RAM).\n",
    "- Analogy: Studying one chapter at a time.\n",
    "\n",
    "### 3. Loss Function (The Scorecard)\n",
    "- Measures how bad the model's prediction is.\n",
    "- Example: MSE (Mean Squared Error) for numbers, CrossEntropy for categories.\n",
    "- Analogy: The grade on a practice test.\n",
    "\n",
    "### 4. Optimizer (The Coach)\n",
    "- The algorithm that updates the weights to reduce the loss.\n",
    "- Example: SGD (Stochastic Gradient Descent), Adam.\n",
    "- Analogy: The coach telling you \"Lean left!\" or \"Pedal harder!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372d1c9",
   "metadata": {},
   "source": [
    "## Part 2: The Intuition (Learning to Ride a Bike)\n",
    "\n",
    "How do you learn to ride a bike?\n",
    "\n",
    "1. **Try**: You get on and pedal. (Forward Pass).\n",
    "2. **Fail**: You fall over. (Compute Loss).\n",
    "3. **Blame**: You realize you leaned too far left. (Compute Gradients).\n",
    "4. **Adjust**: You lean a bit to the right next time. (Update Parameters).\n",
    "5. **Repeat**: You do it again.\n",
    "\n",
    "This is exactly how Neural Networks learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f317a",
   "metadata": {},
   "source": [
    "## Part 3: The Setup (Data, Model, Loss, Optimizer)\n",
    "\n",
    "Before the loop, we need 4 things:\n",
    "\n",
    "1. **Data**: $X$ (Inputs) and $y$ (Targets).\n",
    "2. **Model**: The network.\n",
    "3. **Loss Function**: The Scorecard.\n",
    "4. **Optimizer**: The Coach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5be393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data (Linear Regression: y = 2x + 1)\n",
    "X = torch.linspace(0, 10, 100).view(-1, 1) # 100 inputs\n",
    "y = 2 * X + 1 + torch.randn(X.shape) * 0.5 # 100 targets (with noise)\n",
    "\n",
    "# 2. Model (Linear Layer)\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# 3. Loss Function (MSE: Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 4. Optimizer (SGD: Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212befa5",
   "metadata": {},
   "source": [
    "## Part 4: The Training Loop (The 5 Steps)\n",
    "\n",
    "This loop is the heartbeat of Deep Learning. Memorize these 5 steps.\n",
    "\n",
    "1. **Forward Pass**: `pred = model(X)`\n",
    "2. **Calculate Loss**: `loss = criterion(pred, y)`\n",
    "3. **Zero Gradients**: `optimizer.zero_grad()` (Don't forget!)\n",
    "4. **Backpropagation**: `loss.backward()` (Compute gradients)\n",
    "5. **Step**: `optimizer.step()` (Update weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02377437",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward Pass\n",
    "    predictions = model(X)\n",
    "    \n",
    "    # 2. Calculate Loss\n",
    "    loss = criterion(predictions, y)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # 3. Zero Gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4599e29",
   "metadata": {},
   "source": [
    "## Part 5: Visualization (Did it learn?)\n",
    "\n",
    "Let's see if the model learned the line $y = 2x + 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss Curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss Curve (Lower is Better)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "\n",
    "# Plot Predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X, y, label=\"Data\")\n",
    "with torch.no_grad(): # Don't track gradients for plotting\n",
    "    plt.plot(X, model(X), color='red', label=\"Prediction\")\n",
    "plt.title(\"Model Fit\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check learned parameters\n",
    "print(f\"Learned Weight: {model.weight.item():.2f} (True: 2.0)\")\n",
    "print(f\"Learned Bias: {model.bias.item():.2f} (True: 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "1. **Epoch** = One full pass through the dataset.\n",
    "2. **Loss** = The error metric we want to minimize.\n",
    "3. **Optimizer** = The algorithm (SGD, Adam) that updates weights.\n",
    "4. **The 5 Steps**: Forward -> Loss -> Zero -> Backward -> Step.\n",
    "\n",
    "You have now trained your first AI model from scratch. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
