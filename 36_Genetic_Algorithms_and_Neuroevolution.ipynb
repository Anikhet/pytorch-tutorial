{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Genetic Algorithms and Neuroevolution\n",
    "\n",
    "Genetic Algorithms (GAs) are optimization algorithms inspired by natural selection. **Neuroevolution** applies GAs to evolve neural network weights (or architectures) without using gradient descent.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand genetic algorithm fundamentals (selection, crossover, mutation)\n",
    "- Implement a basic GA for function optimization\n",
    "- Evolve neural network weights to solve control tasks\n",
    "- Learn about NEAT (NeuroEvolution of Augmenting Topologies)\n",
    "- Compare GAs with gradient-based methods and RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Callable\n",
    "import copy\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Genetic Algorithm Fundamentals\n",
    "\n",
    "A genetic algorithm works by:\n",
    "1. **Initialize** a population of candidate solutions (genomes)\n",
    "2. **Evaluate** each individual's fitness\n",
    "3. **Select** the fittest individuals\n",
    "4. **Crossover** pairs to create offspring\n",
    "5. **Mutate** offspring to introduce variation\n",
    "6. **Repeat** until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    \"\"\"Represents a single individual in the population.\"\"\"\n",
    "    \n",
    "    def __init__(self, genome: np.ndarray):\n",
    "        self.genome = genome\n",
    "        self.fitness = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Individual(fitness={self.fitness:.4f})\" if self.fitness else \"Individual(unevaluated)\"\n",
    "\n",
    "\n",
    "class GeneticAlgorithm:\n",
    "    \"\"\"Basic Genetic Algorithm implementation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        genome_size: int,\n",
    "        population_size: int = 50,\n",
    "        mutation_rate: float = 0.1,\n",
    "        mutation_strength: float = 0.5,\n",
    "        elite_ratio: float = 0.1,\n",
    "    ):\n",
    "        self.genome_size = genome_size\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.elite_count = max(1, int(population_size * elite_ratio))\n",
    "        \n",
    "        # Initialize random population\n",
    "        self.population = [\n",
    "            Individual(np.random.randn(genome_size))\n",
    "            for _ in range(population_size)\n",
    "        ]\n",
    "    \n",
    "    def evaluate_population(self, fitness_fn: Callable):\n",
    "        \"\"\"Evaluate fitness of all individuals.\"\"\"\n",
    "        for individual in self.population:\n",
    "            individual.fitness = fitness_fn(individual.genome)\n",
    "    \n",
    "    def tournament_selection(self, tournament_size: int = 3) -> Individual:\n",
    "        \"\"\"Select individual via tournament selection.\"\"\"\n",
    "        tournament = np.random.choice(self.population, size=tournament_size, replace=False)\n",
    "        return max(tournament, key=lambda x: x.fitness)\n",
    "    \n",
    "    def crossover(self, parent1: Individual, parent2: Individual) -> Individual:\n",
    "        \"\"\"Single-point crossover between two parents.\"\"\"\n",
    "        crossover_point = np.random.randint(1, self.genome_size)\n",
    "        child_genome = np.concatenate([\n",
    "            parent1.genome[:crossover_point],\n",
    "            parent2.genome[crossover_point:]\n",
    "        ])\n",
    "        return Individual(child_genome)\n",
    "    \n",
    "    def mutate(self, individual: Individual) -> Individual:\n",
    "        \"\"\"Apply Gaussian mutation to genome.\"\"\"\n",
    "        mask = np.random.random(self.genome_size) < self.mutation_rate\n",
    "        mutation = np.random.randn(self.genome_size) * self.mutation_strength\n",
    "        new_genome = individual.genome + mask * mutation\n",
    "        return Individual(new_genome)\n",
    "    \n",
    "    def evolve_generation(self, fitness_fn: Callable):\n",
    "        \"\"\"Create next generation through selection, crossover, and mutation.\"\"\"\n",
    "        # Evaluate current population\n",
    "        self.evaluate_population(fitness_fn)\n",
    "        \n",
    "        # Sort by fitness (descending)\n",
    "        self.population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        \n",
    "        # Keep elite individuals\n",
    "        new_population = [copy.deepcopy(ind) for ind in self.population[:self.elite_count]]\n",
    "        \n",
    "        # Fill rest with offspring\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent1 = self.tournament_selection()\n",
    "            parent2 = self.tournament_selection()\n",
    "            child = self.crossover(parent1, parent2)\n",
    "            child = self.mutate(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        self.population = new_population\n",
    "    \n",
    "    def get_best(self) -> Individual:\n",
    "        \"\"\"Return the best individual in the population.\"\"\"\n",
    "        return max(self.population, key=lambda x: x.fitness if x.fitness else float('-inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Optimizing a Simple Function\n",
    "\n",
    "Let's use GA to find the minimum of the Rastrigin function (a challenging multi-modal function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x: np.ndarray) -> float:\n",
    "    \"\"\"Rastrigin function - global minimum at x=0.\"\"\"\n",
    "    A = 10\n",
    "    n = len(x)\n",
    "    # Negate because GA maximizes fitness\n",
    "    return -(A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x)))\n",
    "\n",
    "# Run GA\n",
    "ga = GeneticAlgorithm(\n",
    "    genome_size=10,\n",
    "    population_size=100,\n",
    "    mutation_rate=0.2,\n",
    "    mutation_strength=0.3,\n",
    ")\n",
    "\n",
    "history = []\n",
    "for generation in range(100):\n",
    "    ga.evolve_generation(rastrigin)\n",
    "    best = ga.get_best()\n",
    "    history.append(-best.fitness)  # Convert back to actual function value\n",
    "    \n",
    "    if generation % 20 == 0:\n",
    "        print(f\"Gen {generation}: Best fitness = {-best.fitness:.4f}\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Best Rastrigin Value')\n",
    "plt.title('GA Optimization of Rastrigin Function')\n",
    "plt.axhline(y=0, color='r', linestyle='--', label='Global minimum')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal solution: {ga.get_best().genome[:5]}...\")  # Show first 5 values\n",
    "print(f\"Final fitness: {-ga.get_best().fitness:.6f} (optimal: 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selection Strategies\n",
    "\n",
    "Different selection methods have different properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(population: List[Individual]) -> Individual:\n",
    "    \"\"\"\n",
    "    Fitness-proportionate selection.\n",
    "    Higher fitness = higher probability of selection.\n",
    "    \"\"\"\n",
    "    fitness_values = np.array([ind.fitness for ind in population])\n",
    "    # Shift to positive if needed\n",
    "    min_fitness = fitness_values.min()\n",
    "    if min_fitness < 0:\n",
    "        fitness_values = fitness_values - min_fitness + 1e-6\n",
    "    \n",
    "    probabilities = fitness_values / fitness_values.sum()\n",
    "    return np.random.choice(population, p=probabilities)\n",
    "\n",
    "\n",
    "def rank_selection(population: List[Individual]) -> Individual:\n",
    "    \"\"\"\n",
    "    Rank-based selection.\n",
    "    Selection probability based on rank, not raw fitness.\n",
    "    Helps prevent premature convergence.\n",
    "    \"\"\"\n",
    "    sorted_pop = sorted(population, key=lambda x: x.fitness)\n",
    "    ranks = np.arange(1, len(population) + 1)\n",
    "    probabilities = ranks / ranks.sum()\n",
    "    return np.random.choice(sorted_pop, p=probabilities)\n",
    "\n",
    "\n",
    "def truncation_selection(population: List[Individual], top_ratio: float = 0.5) -> Individual:\n",
    "    \"\"\"\n",
    "    Select only from top performers.\n",
    "    Simple but can lead to loss of diversity.\n",
    "    \"\"\"\n",
    "    sorted_pop = sorted(population, key=lambda x: x.fitness, reverse=True)\n",
    "    cutoff = max(1, int(len(population) * top_ratio))\n",
    "    return np.random.choice(sorted_pop[:cutoff])\n",
    "\n",
    "\n",
    "# Compare selection pressures\n",
    "print(\"Selection Strategy Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"| Strategy    | Pressure | Diversity | Speed |\")\n",
    "print(\"-\" * 50)\n",
    "print(\"| Tournament  | Medium   | Good      | Fast  |\")\n",
    "print(\"| Roulette    | Variable | Medium    | Fast  |\")\n",
    "print(\"| Rank        | Medium   | Good      | Fast  |\")\n",
    "print(\"| Truncation  | High     | Low       | Fast  |\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neuroevolution: Evolving Neural Networks\n",
    "\n",
    "Now let's evolve neural network weights to solve a control task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvableNetwork(nn.Module):\n",
    "    \"\"\"A neural network whose weights can be set from a flat genome.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.genome_size = self._count_parameters()\n",
    "    \n",
    "    def _count_parameters(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def set_weights_from_genome(self, genome: np.ndarray):\n",
    "        \"\"\"Set network weights from a flat numpy array.\"\"\"\n",
    "        idx = 0\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                param_size = param.numel()\n",
    "                param_data = genome[idx:idx + param_size]\n",
    "                param.copy_(torch.tensor(param_data, dtype=torch.float32).view(param.shape))\n",
    "                idx += param_size\n",
    "    \n",
    "    def get_genome(self) -> np.ndarray:\n",
    "        \"\"\"Extract weights as a flat numpy array.\"\"\"\n",
    "        return np.concatenate([p.data.cpu().numpy().flatten() for p in self.parameters()])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Example network\n",
    "net = EvolvableNetwork(input_size=4, hidden_size=8, output_size=2)\n",
    "print(f\"Network has {net.genome_size} parameters (genes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Control Task: Balance a Pole\n",
    "\n",
    "We'll simulate a simple cart-pole-like environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePoleEnvironment:\n",
    "    \"\"\"\n",
    "    Simplified pole balancing task.\n",
    "    State: [position, velocity, angle, angular_velocity]\n",
    "    Action: force applied to cart [-1, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "        # Physics constants\n",
    "        self.gravity = 9.8\n",
    "        self.cart_mass = 1.0\n",
    "        self.pole_mass = 0.1\n",
    "        self.pole_length = 0.5\n",
    "        self.dt = 0.02\n",
    "    \n",
    "    def reset(self) -> np.ndarray:\n",
    "        # Small random initial state\n",
    "        self.state = np.random.uniform(-0.05, 0.05, size=4)\n",
    "        return self.state.copy()\n",
    "    \n",
    "    def step(self, action: float) -> Tuple[np.ndarray, float, bool]:\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = np.clip(action, -1, 1) * 10  # Scale action\n",
    "        \n",
    "        # Simplified physics\n",
    "        cos_theta = np.cos(theta)\n",
    "        sin_theta = np.sin(theta)\n",
    "        \n",
    "        total_mass = self.cart_mass + self.pole_mass\n",
    "        pole_mass_length = self.pole_mass * self.pole_length\n",
    "        \n",
    "        # Angular acceleration\n",
    "        temp = (force + pole_mass_length * theta_dot**2 * sin_theta) / total_mass\n",
    "        theta_acc = (self.gravity * sin_theta - cos_theta * temp) / (\n",
    "            self.pole_length * (4/3 - self.pole_mass * cos_theta**2 / total_mass)\n",
    "        )\n",
    "        \n",
    "        # Linear acceleration\n",
    "        x_acc = temp - pole_mass_length * theta_acc * cos_theta / total_mass\n",
    "        \n",
    "        # Update state\n",
    "        x += self.dt * x_dot\n",
    "        x_dot += self.dt * x_acc\n",
    "        theta += self.dt * theta_dot\n",
    "        theta_dot += self.dt * theta_acc\n",
    "        \n",
    "        self.state = np.array([x, x_dot, theta, theta_dot])\n",
    "        \n",
    "        # Check termination\n",
    "        done = abs(x) > 2.4 or abs(theta) > 0.21  # ~12 degrees\n",
    "        reward = 1.0 if not done else 0.0\n",
    "        \n",
    "        return self.state.copy(), reward, done\n",
    "\n",
    "\n",
    "def evaluate_network(network: EvolvableNetwork, env: SimplePoleEnvironment, max_steps: int = 500) -> float:\n",
    "    \"\"\"Evaluate network on the pole balancing task.\"\"\"\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        # Get action from network\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "            action = network(state_tensor).item()\n",
    "        \n",
    "        state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuroevolution Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuroevolution:\n",
    "    \"\"\"Evolve neural network weights using genetic algorithms.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        network_template: EvolvableNetwork,\n",
    "        population_size: int = 50,\n",
    "        mutation_rate: float = 0.1,\n",
    "        mutation_strength: float = 0.2,\n",
    "        elite_ratio: float = 0.1,\n",
    "    ):\n",
    "        self.network_template = network_template\n",
    "        self.genome_size = network_template.genome_size\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.elite_count = max(1, int(population_size * elite_ratio))\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = [\n",
    "            Individual(np.random.randn(self.genome_size) * 0.5)\n",
    "            for _ in range(population_size)\n",
    "        ]\n",
    "    \n",
    "    def evaluate_individual(self, genome: np.ndarray, env: SimplePoleEnvironment) -> float:\n",
    "        \"\"\"Evaluate a single genome.\"\"\"\n",
    "        network = copy.deepcopy(self.network_template)\n",
    "        network.set_weights_from_genome(genome)\n",
    "        \n",
    "        # Average over multiple runs for stability\n",
    "        total_fitness = 0\n",
    "        n_runs = 3\n",
    "        for _ in range(n_runs):\n",
    "            total_fitness += evaluate_network(network, env)\n",
    "        \n",
    "        return total_fitness / n_runs\n",
    "    \n",
    "    def evolve_generation(self, env: SimplePoleEnvironment):\n",
    "        \"\"\"Evolve one generation.\"\"\"\n",
    "        # Evaluate fitness\n",
    "        for individual in self.population:\n",
    "            individual.fitness = self.evaluate_individual(individual.genome, env)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        self.population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        \n",
    "        # Keep elites\n",
    "        new_population = [copy.deepcopy(ind) for ind in self.population[:self.elite_count]]\n",
    "        \n",
    "        # Create offspring\n",
    "        while len(new_population) < self.population_size:\n",
    "            # Tournament selection\n",
    "            tournament = np.random.choice(self.population, size=3, replace=False)\n",
    "            parent1 = max(tournament, key=lambda x: x.fitness)\n",
    "            tournament = np.random.choice(self.population, size=3, replace=False)\n",
    "            parent2 = max(tournament, key=lambda x: x.fitness)\n",
    "            \n",
    "            # Crossover\n",
    "            crossover_point = np.random.randint(1, self.genome_size)\n",
    "            child_genome = np.concatenate([\n",
    "                parent1.genome[:crossover_point],\n",
    "                parent2.genome[crossover_point:]\n",
    "            ])\n",
    "            \n",
    "            # Mutation\n",
    "            mask = np.random.random(self.genome_size) < self.mutation_rate\n",
    "            mutation = np.random.randn(self.genome_size) * self.mutation_strength\n",
    "            child_genome = child_genome + mask * mutation\n",
    "            \n",
    "            new_population.append(Individual(child_genome))\n",
    "        \n",
    "        self.population = new_population\n",
    "    \n",
    "    def get_best_network(self) -> EvolvableNetwork:\n",
    "        \"\"\"Return the best network in the population.\"\"\"\n",
    "        best = max(self.population, key=lambda x: x.fitness if x.fitness else float('-inf'))\n",
    "        network = copy.deepcopy(self.network_template)\n",
    "        network.set_weights_from_genome(best.genome)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network template and environment\n",
    "network_template = EvolvableNetwork(input_size=4, hidden_size=8, output_size=1)\n",
    "env = SimplePoleEnvironment()\n",
    "\n",
    "# Initialize neuroevolution\n",
    "neuro = Neuroevolution(\n",
    "    network_template=network_template,\n",
    "    population_size=50,\n",
    "    mutation_rate=0.1,\n",
    "    mutation_strength=0.2,\n",
    ")\n",
    "\n",
    "print(f\"Evolving networks with {network_template.genome_size} parameters...\\n\")\n",
    "\n",
    "# Evolution loop\n",
    "best_fitness_history = []\n",
    "avg_fitness_history = []\n",
    "\n",
    "for generation in range(50):\n",
    "    neuro.evolve_generation(env)\n",
    "    \n",
    "    # Track statistics\n",
    "    fitness_values = [ind.fitness for ind in neuro.population]\n",
    "    best_fitness = max(fitness_values)\n",
    "    avg_fitness = np.mean(fitness_values)\n",
    "    \n",
    "    best_fitness_history.append(best_fitness)\n",
    "    avg_fitness_history.append(avg_fitness)\n",
    "    \n",
    "    if generation % 10 == 0:\n",
    "        print(f\"Gen {generation}: Best={best_fitness:.1f}, Avg={avg_fitness:.1f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(best_fitness_history, label='Best Fitness')\n",
    "plt.plot(avg_fitness_history, label='Average Fitness', alpha=0.7)\n",
    "plt.axhline(y=500, color='r', linestyle='--', label='Max possible (500)')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness (steps balanced)')\n",
    "plt.title('Neuroevolution: Pole Balancing')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal best fitness: {best_fitness_history[-1]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NEAT: NeuroEvolution of Augmenting Topologies\n",
    "\n",
    "NEAT evolves both weights AND network topology (adding nodes and connections over time).\n",
    "\n",
    "### Key NEAT Concepts:\n",
    "\n",
    "1. **Historical Markings**: Track when genes were created to align genomes during crossover\n",
    "2. **Speciation**: Group similar networks to protect innovation\n",
    "3. **Complexification**: Start simple, add complexity only when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEAT is complex to implement from scratch. Here's a simplified illustration:\n",
    "\n",
    "class SimplifiedNEATGene:\n",
    "    \"\"\"Represents a connection gene in NEAT.\"\"\"\n",
    "    global_innovation = 0\n",
    "    \n",
    "    def __init__(self, in_node: int, out_node: int, weight: float, enabled: bool = True):\n",
    "        self.in_node = in_node\n",
    "        self.out_node = out_node\n",
    "        self.weight = weight\n",
    "        self.enabled = enabled\n",
    "        self.innovation = SimplifiedNEATGene.global_innovation\n",
    "        SimplifiedNEATGene.global_innovation += 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        status = \"ON\" if self.enabled else \"OFF\"\n",
    "        return f\"Gene({self.in_node}->{self.out_node}, w={self.weight:.2f}, {status}, inn={self.innovation})\"\n",
    "\n",
    "\n",
    "# Example genome\n",
    "print(\"NEAT Genome Example:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "genome = [\n",
    "    SimplifiedNEATGene(1, 4, 0.5),   # Input 1 -> Hidden 4\n",
    "    SimplifiedNEATGene(2, 4, -0.3),  # Input 2 -> Hidden 4\n",
    "    SimplifiedNEATGene(4, 5, 0.8),   # Hidden 4 -> Output 5\n",
    "    SimplifiedNEATGene(1, 5, 0.2),   # Direct connection: Input 1 -> Output 5\n",
    "]\n",
    "\n",
    "for gene in genome:\n",
    "    print(gene)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"NEAT allows the network to grow over generations!\")\n",
    "print(\"New nodes and connections can be added via mutation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evolution Strategies (ES) - Modern Alternative\n",
    "\n",
    "Evolution Strategies are a related approach that's simpler and often works better for neuroevolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolutionStrategy:\n",
    "    \"\"\"\n",
    "    Simple Evolution Strategy (1+1)-ES or (mu, lambda)-ES.\n",
    "    No crossover, just mutation and selection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        genome_size: int,\n",
    "        population_size: int = 50,\n",
    "        sigma: float = 0.1,\n",
    "        learning_rate: float = 0.01,\n",
    "    ):\n",
    "        self.genome_size = genome_size\n",
    "        self.population_size = population_size\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize mean of distribution\n",
    "        self.theta = np.zeros(genome_size)\n",
    "    \n",
    "    def sample_population(self) -> List[np.ndarray]:\n",
    "        \"\"\"Sample population around current mean.\"\"\"\n",
    "        noise = [np.random.randn(self.genome_size) for _ in range(self.population_size)]\n",
    "        population = [self.theta + self.sigma * n for n in noise]\n",
    "        return population, noise\n",
    "    \n",
    "    def update(self, fitness_values: np.ndarray, noise: List[np.ndarray]):\n",
    "        \"\"\"Update mean using fitness-weighted noise.\"\"\"\n",
    "        # Normalize fitness\n",
    "        fitness_values = np.array(fitness_values)\n",
    "        fitness_values = (fitness_values - fitness_values.mean()) / (fitness_values.std() + 1e-8)\n",
    "        \n",
    "        # Weighted sum of noise vectors\n",
    "        gradient = np.zeros(self.genome_size)\n",
    "        for f, n in zip(fitness_values, noise):\n",
    "            gradient += f * n\n",
    "        gradient /= self.population_size * self.sigma\n",
    "        \n",
    "        # Update\n",
    "        self.theta += self.learning_rate * gradient\n",
    "\n",
    "print(\"Evolution Strategies (ES):\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Sample population: theta + sigma * noise\")\n",
    "print(\"2. Evaluate fitness of each sample\")\n",
    "print(\"3. Update theta toward high-fitness samples\")\n",
    "print(\"4. Repeat\")\n",
    "print(\"\\nAdvantages over GA:\")\n",
    "print(\"- Simpler (no crossover)\")\n",
    "print(\"- Highly parallelizable\")\n",
    "print(\"- Works well for high-dimensional problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison: GA vs Gradient Descent vs RL\n",
    "\n",
    "When should you use each approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"\"\"\n",
    "| Aspect              | Genetic Algorithm    | Gradient Descent     | RL (Policy Gradient)  |\n",
    "|---------------------|---------------------|----------------------|----------------------|\n",
    "| **Gradients needed**| No                  | Yes                  | Yes                  |\n",
    "| **Parallelization** | Excellent           | Limited              | Good                 |\n",
    "| **Local minima**    | Escapes well        | Can get stuck        | Can get stuck        |\n",
    "| **Sample efficiency**| Low                | High                 | Medium               |\n",
    "| **Sparse rewards**  | Handles well        | N/A                  | Struggles            |\n",
    "| **Scalability**     | Moderate            | Excellent            | Good                 |\n",
    "| **Best for**        | Non-differentiable, | Supervised learning, | Sequential decisions,|\n",
    "|                     | multi-modal         | differentiable       | long-term rewards    |\n",
    "\n",
    "Use GA/Neuroevolution when:\n",
    "- Reward is sparse or deceptive\n",
    "- Environment is non-differentiable\n",
    "- You have lots of compute for parallel evaluation\n",
    "- Problem is multi-modal (many local optima)\n",
    "- You want to evolve architecture, not just weights\n",
    "\n",
    "Use Gradient-based methods when:\n",
    "- You have gradients (supervised learning)\n",
    "- Sample efficiency matters\n",
    "- Problem is high-dimensional\n",
    "- You have limited compute\n",
    "\"\"\"\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FAANG Interview Questions\n",
    "\n",
    "### Q1: How does a genetic algorithm work? What are the main operators?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "GA is an optimization algorithm inspired by natural selection:\n",
    "\n",
    "1. **Initialize**: Create random population of candidate solutions (genomes)\n",
    "2. **Evaluate**: Calculate fitness of each individual\n",
    "3. **Select**: Choose parents based on fitness (tournament, roulette wheel, etc.)\n",
    "4. **Crossover**: Combine parent genomes to create offspring\n",
    "5. **Mutate**: Add random variations to offspring\n",
    "6. **Replace**: Form new generation, possibly keeping elites\n",
    "7. **Repeat** until convergence\n",
    "\n",
    "**Key operators**:\n",
    "- Selection: Tournament, roulette wheel, rank-based\n",
    "- Crossover: Single-point, two-point, uniform\n",
    "- Mutation: Gaussian noise, bit flip, gene swap\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: What is neuroevolution and how does it differ from backpropagation?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "**Neuroevolution**: Evolving neural network weights (and/or architecture) using evolutionary algorithms instead of gradient descent.\n",
    "\n",
    "| Aspect | Neuroevolution | Backpropagation |\n",
    "|--------|---------------|----------------|\n",
    "| Gradients | Not required | Required |\n",
    "| Parallelization | Excellent | Limited |\n",
    "| Credit assignment | Population-level | Per-sample |\n",
    "| Architecture | Can evolve | Fixed |\n",
    "| Sample efficiency | Low | High |\n",
    "| Non-differentiable | Handles well | Cannot handle |\n",
    "\n",
    "**Use neuroevolution when**: Reward is sparse/non-differentiable, want to evolve architecture, or have parallel compute.\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: What is NEAT and why is speciation important?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "**NEAT** (NeuroEvolution of Augmenting Topologies) evolves both weights AND network topology.\n",
    "\n",
    "**Key innovations**:\n",
    "1. **Historical markings**: Track when genes were created for alignment during crossover\n",
    "2. **Speciation**: Group similar networks together\n",
    "3. **Complexification**: Start simple, add complexity only when beneficial\n",
    "\n",
    "**Why speciation matters**:\n",
    "- New innovations (added nodes/connections) initially hurt fitness\n",
    "- Without protection, innovations die before they can optimize\n",
    "- Speciation lets innovations compete within their niche, giving them time to improve\n",
    "\n",
    "---\n",
    "\n",
    "### Q4: Explain the exploration-exploitation tradeoff in GA.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "**Exploration**: Searching new areas of the solution space\n",
    "**Exploitation**: Refining known good solutions\n",
    "\n",
    "**GA levers**:\n",
    "| Parameter | High value = More... |\n",
    "|-----------|---------------------|\n",
    "| Mutation rate | Exploration |\n",
    "| Mutation strength | Exploration |\n",
    "| Population size | Exploration |\n",
    "| Selection pressure | Exploitation |\n",
    "| Elite ratio | Exploitation |\n",
    "\n",
    "**Balancing strategies**:\n",
    "- Start with high exploration, reduce over time\n",
    "- Adaptive mutation (increase when stuck)\n",
    "- Diversity maintenance (niching, crowding)\n",
    "\n",
    "---\n",
    "\n",
    "### Q5: What are Evolution Strategies and how do they differ from GA?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "**Evolution Strategies (ES)**:\n",
    "- Sample population: theta + sigma * noise\n",
    "- Evaluate fitness\n",
    "- Update theta toward high-fitness samples\n",
    "- No crossover, just mutation and selection\n",
    "\n",
    "**Key differences from GA**:\n",
    "| Aspect | GA | ES |\n",
    "|--------|----|----|  \n",
    "| Crossover | Yes | No |\n",
    "| Representation | Discrete genomes | Continuous distribution |\n",
    "| Update | Replace population | Gradient-like update |\n",
    "| Parallelization | Good | Excellent |\n",
    "\n",
    "**Modern ES (like OpenAI ES)**: Can match RL performance on some tasks with better parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "1. **Genetic Algorithms** optimize without gradients using selection, crossover, and mutation\n",
    "2. **Neuroevolution** applies GAs to neural network weights (and potentially architecture)\n",
    "3. **Selection strategies** (tournament, roulette, rank) control exploration-exploitation tradeoff\n",
    "4. **NEAT** evolves topology, using speciation to protect innovation\n",
    "5. **Evolution Strategies** are simpler (no crossover) and highly parallelizable\n",
    "6. **Use GAs/ES when**: gradients unavailable, rewards sparse, architecture matters\n",
    "7. **Elitism** preserves best solutions, mutation introduces variation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
