{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Neural Cellular Automata\n",
    "\n",
    "Neural Cellular Automata (NCA) combine the local update rules of cellular automata with learnable neural networks. They can learn to grow patterns, regenerate from damage, and create complex textures from simple rules.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand classical cellular automata (Conway's Game of Life)\n",
    "- Make cellular automata differentiable for training\n",
    "- Implement perception using Sobel filters\n",
    "- Build and train a Neural CA to grow patterns\n",
    "- Understand regeneration and self-organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classical Cellular Automata\n",
    "\n",
    "A cellular automaton is a grid of cells, where each cell's next state depends only on its current state and neighbors.\n",
    "\n",
    "**Conway's Game of Life rules**:\n",
    "- Live cell with 2-3 neighbors survives\n",
    "- Dead cell with exactly 3 neighbors becomes alive\n",
    "- All other cells die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_of_life_step(grid: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"One step of Conway's Game of Life.\"\"\"\n",
    "    kernel = torch.tensor([[1, 1, 1],\n",
    "                          [1, 0, 1],\n",
    "                          [1, 1, 1]], dtype=torch.float32)\n",
    "    kernel = kernel.view(1, 1, 3, 3)\n",
    "    \n",
    "    grid_4d = grid.float().view(1, 1, *grid.shape)\n",
    "    neighbors = F.conv2d(grid_4d, kernel, padding=1).squeeze()\n",
    "    \n",
    "    birth = (grid == 0) & (neighbors == 3)\n",
    "    survive = (grid == 1) & ((neighbors == 2) | (neighbors == 3))\n",
    "    \n",
    "    return (birth | survive).float()\n",
    "\n",
    "# Create initial state with a glider\n",
    "grid_size = 32\n",
    "initial = torch.zeros(grid_size, grid_size)\n",
    "glider = torch.tensor([[0, 1, 0],\n",
    "                       [0, 0, 1],\n",
    "                       [1, 1, 1]], dtype=torch.float32)\n",
    "initial[5:8, 5:8] = glider\n",
    "\n",
    "# Run simulation\n",
    "history = [initial.clone()]\n",
    "state = initial.clone()\n",
    "for _ in range(50):\n",
    "    state = game_of_life_step(state)\n",
    "    history.append(state.clone())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, step in enumerate([0, 10, 20, 30, 50]):\n",
    "    axes[i].imshow(history[step].numpy(), cmap='binary')\n",
    "    axes[i].set_title(f'Step {step}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(\"Conway's Game of Life - Glider\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making CA Differentiable\n",
    "\n",
    "To learn CA rules, we need:\n",
    "1. **Continuous state**: Not just 0/1, but real values\n",
    "2. **Smooth update function**: Learnable neural network\n",
    "3. **Differentiable loss**: Compare to target pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 16  # 4 visible (RGBA) + 12 hidden\n",
    "\n",
    "def create_seed(size: int, num_channels: int = NUM_CHANNELS) -> torch.Tensor:\n",
    "    \"\"\"Create a seed state with a single active cell in the center.\"\"\"\n",
    "    state = torch.zeros(1, num_channels, size, size)\n",
    "    center = size // 2\n",
    "    state[0, 3, center, center] = 1.0  # Alpha channel\n",
    "    return state\n",
    "\n",
    "def get_visible_state(state: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Extract RGBA channels from state.\"\"\"\n",
    "    rgba = state[:, :4, :, :]\n",
    "    return torch.clamp(rgba, 0, 1)\n",
    "\n",
    "# Visualize seed\n",
    "seed = create_seed(64)\n",
    "visible = get_visible_state(seed)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(visible[0, 3].numpy(), cmap='gray')\n",
    "plt.title('Seed State (Alpha Channel)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(f\"State shape: {seed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perception: Sobel Filters\n",
    "\n",
    "Each cell needs to perceive its neighborhood. We use **Sobel filters** to detect gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptionModule(nn.Module):\n",
    "    \"\"\"Perceive local neighborhood using Sobel filters.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels: int = NUM_CHANNELS):\n",
    "        super().__init__()\n",
    "        \n",
    "        sobel_x = torch.tensor([[-1, 0, 1],\n",
    "                                [-2, 0, 2],\n",
    "                                [-1, 0, 1]], dtype=torch.float32) / 8.0\n",
    "        \n",
    "        sobel_y = torch.tensor([[-1, -2, -1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 2, 1]], dtype=torch.float32) / 8.0\n",
    "        \n",
    "        identity = torch.tensor([[0, 0, 0],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 0]], dtype=torch.float32)\n",
    "        \n",
    "        filters = torch.stack([identity, sobel_x, sobel_y])\n",
    "        self.filters = nn.Parameter(\n",
    "            filters.repeat(num_channels, 1, 1).view(-1, 1, 3, 3),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        self.num_channels = num_channels\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        perceived = F.conv2d(x, self.filters, padding=1, groups=self.num_channels)\n",
    "        return perceived\n",
    "\n",
    "# Demonstrate perception\n",
    "perception = PerceptionModule()\n",
    "test_state = torch.zeros(1, NUM_CHANNELS, 32, 32)\n",
    "test_state[0, 3, 10:22, 10:22] = 1.0\n",
    "\n",
    "perceived = perception(test_state)\n",
    "print(f\"Input shape: {test_state.shape}\")\n",
    "print(f\"Perceived shape: {perceived.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural CA Update Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCA(nn.Module):\n",
    "    \"\"\"Neural Cellular Automaton.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels: int = NUM_CHANNELS, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_channels = num_channels\n",
    "        self.perception = PerceptionModule(num_channels)\n",
    "        \n",
    "        perception_dim = num_channels * 3\n",
    "        \n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Conv2d(perception_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, num_channels, 1),\n",
    "        )\n",
    "        \n",
    "        nn.init.zeros_(self.update_net[-1].weight)\n",
    "        nn.init.zeros_(self.update_net[-1].bias)\n",
    "    \n",
    "    def get_alive_mask(self, state: torch.Tensor, threshold: float = 0.1) -> torch.Tensor:\n",
    "        alpha = state[:, 3:4, :, :]\n",
    "        alive = F.max_pool2d(alpha, 3, stride=1, padding=1) > threshold\n",
    "        return alive.float()\n",
    "    \n",
    "    def forward(self, state: torch.Tensor, update_rate: float = 0.5) -> torch.Tensor:\n",
    "        pre_alive = self.get_alive_mask(state)\n",
    "        perceived = self.perception(state)\n",
    "        delta = self.update_net(perceived)\n",
    "        \n",
    "        if self.training:\n",
    "            update_mask = (torch.rand_like(state[:, :1, :, :]) < update_rate).float()\n",
    "        else:\n",
    "            update_mask = 1.0\n",
    "        \n",
    "        state = state + delta * update_mask\n",
    "        post_alive = self.get_alive_mask(state)\n",
    "        alive_mask = pre_alive * post_alive\n",
    "        state = state * alive_mask\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def run_steps(self, state: torch.Tensor, steps: int) -> torch.Tensor:\n",
    "        for _ in range(steps):\n",
    "            state = self(state)\n",
    "        return state\n",
    "\n",
    "nca = NeuralCA().to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in nca.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training to Grow a Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_circle(size: int = 64) -> torch.Tensor:\n",
    "    \"\"\"Create a simple circle target pattern.\"\"\"\n",
    "    target = torch.zeros(1, 4, size, size)\n",
    "    center = size // 2\n",
    "    \n",
    "    y, x = torch.meshgrid(torch.arange(size), torch.arange(size), indexing='ij')\n",
    "    y, x = y.float(), x.float()\n",
    "    \n",
    "    dist_from_center = torch.sqrt((x - center)**2 + (y - center)**2)\n",
    "    circle_radius = size * 0.35\n",
    "    circle_mask = dist_from_center < circle_radius\n",
    "    \n",
    "    target[0, 0][circle_mask] = 1.0  # R\n",
    "    target[0, 1][circle_mask] = 0.5  # G\n",
    "    target[0, 2][circle_mask] = 0.0  # B\n",
    "    target[0, 3][circle_mask] = 1.0  # A\n",
    "    \n",
    "    return target\n",
    "\n",
    "target = create_target_circle(64).to(device)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "img = target[0].permute(1, 2, 0).cpu().numpy()\n",
    "plt.imshow(img)\n",
    "plt.title('Target Pattern')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nca(model, target, num_epochs=500, pool_size=256, batch_size=4, lr=2e-3):\n",
    "    \"\"\"Train NCA using a pool of states.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    size = target.shape[-1]\n",
    "    pool = create_seed(size).repeat(pool_size, 1, 1, 1).to(device)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        batch_indices = torch.randint(0, pool_size, (batch_size,))\n",
    "        batch = pool[batch_indices].clone()\n",
    "        num_steps = torch.randint(64, 96, (1,)).item()\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            batch = model(batch)\n",
    "        \n",
    "        visible = get_visible_state(batch)\n",
    "        loss = F.mse_loss(visible, target.expand(batch_size, -1, -1, -1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pool[batch_indices] = batch.detach()\n",
    "            batch_losses = F.mse_loss(visible, target.expand(batch_size, -1, -1, -1), reduction='none')\n",
    "            batch_losses = batch_losses.mean(dim=(1, 2, 3))\n",
    "            worst_idx = batch_indices[batch_losses.argmax()]\n",
    "            pool[worst_idx] = create_seed(size).to(device).squeeze(0)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "nca = NeuralCA().to(device)\n",
    "print(\"Training Neural CA...\")\n",
    "losses = train_nca(nca, target, num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_growth(model, size=64, steps=100):\n",
    "    \"\"\"Visualize the NCA growing from seed.\"\"\"\n",
    "    model.eval()\n",
    "    state = create_seed(size).to(device)\n",
    "    history = [get_visible_state(state).cpu()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            state = model(state)\n",
    "            history.append(get_visible_state(state).cpu())\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 6, figsize=(15, 3))\n",
    "    for i, step in enumerate([0, 20, 40, 60, 80, 100]):\n",
    "        img = history[step][0].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Step {step}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('NCA Growth from Seed')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_growth(nca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regeneration: Self-Repair from Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regeneration(model, size=64, grow_steps=100, regen_steps=100):\n",
    "    \"\"\"Test NCA regeneration after damage.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    state = create_seed(size).to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(grow_steps):\n",
    "            state = model(state)\n",
    "    \n",
    "    grown = state.clone()\n",
    "    damaged = state.clone()\n",
    "    damaged[:, :, 20:44, 20:44] = 0\n",
    "    \n",
    "    regenerating = damaged.clone()\n",
    "    regen_history = [get_visible_state(regenerating).cpu()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(regen_steps):\n",
    "            regenerating = model(regenerating)\n",
    "            regen_history.append(get_visible_state(regenerating).cpu())\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    axes[0, 0].imshow(get_visible_state(grown)[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 0].set_title('Fully Grown')\n",
    "    axes[0, 1].imshow(get_visible_state(damaged)[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 1].set_title('After Damage')\n",
    "    for i in range(3):\n",
    "        axes[0, i+2].axis('off')\n",
    "    \n",
    "    for i, step in enumerate([0, 25, 50, 75, 100]):\n",
    "        axes[1, i].imshow(regen_history[step][0].permute(1, 2, 0).numpy())\n",
    "        axes[1, i].set_title(f'Regen Step {step}')\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('NCA Regeneration After Damage')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_regeneration(nca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. FAANG Interview Questions\n",
    "\n",
    "### Q1: What is a Neural Cellular Automaton and how does it differ from classical CA?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "**Classical CA** (e.g., Game of Life):\n",
    "- Fixed, hand-designed rules\n",
    "- Discrete states (0 or 1)\n",
    "- Non-differentiable\n",
    "\n",
    "**Neural CA**:\n",
    "- Learnable rules (neural network)\n",
    "- Continuous states (real values)\n",
    "- Fully differentiable -> can train with gradient descent\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: Why use Sobel filters for perception?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "Sobel filters detect gradients in the neighborhood:\n",
    "- Identity: Current cell value\n",
    "- Sobel-X: Horizontal gradient\n",
    "- Sobel-Y: Vertical gradient\n",
    "\n",
    "Useful because gradients indicate direction of change.\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: How does pool-based training work?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "1. Maintain pool of N states\n",
    "2. Sample batch from pool\n",
    "3. Run for random number of steps\n",
    "4. Compute loss and update\n",
    "5. Put updated states back in pool\n",
    "6. Replace worst sample with fresh seed\n",
    "\n",
    "This tests persistence and robustness.\n",
    "\n",
    "---\n",
    "\n",
    "### Q4: Why do NCAs regenerate?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "- Local rules: cells only see neighbors\n",
    "- Same update everywhere\n",
    "- Pool training exposes model to partial states\n",
    "- Target pattern becomes a stable attractor\n",
    "\n",
    "---\n",
    "\n",
    "### Q5: Applications of Neural CA?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "- Texture synthesis\n",
    "- Pattern growth\n",
    "- Self-repair systems\n",
    "- Morphogenesis modeling\n",
    "- Generative art\n",
    "- Decentralized computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "1. **Neural CA** combine cellular automata with learnable neural networks\n",
    "2. **Perception** uses Sobel filters to sense local gradients\n",
    "3. **Update rule** is a small network applied to each cell\n",
    "4. **Residual updates** with stochastic masks enable stable growth\n",
    "5. **Pool-based training** tests persistence and robustness\n",
    "6. **Regeneration** emerges naturally from local rules\n",
    "7. **Self-organization** produces complex patterns from simple seeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
