{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Neural Cellular Automata\n",
    "\n",
    "Neural Cellular Automata (NCA) combine the local update rules of cellular automata with learnable neural networks. They can learn to grow patterns, regenerate from damage, and create complex textures from simple rules.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand classical cellular automata (Conway's Game of Life)\n",
    "- Make cellular automata differentiable for training\n",
    "- Implement perception using Sobel filters\n",
    "- Build and train a Neural CA to grow patterns\n",
    "- Understand regeneration and self-organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Classical Cellular Automata\n\nA cellular automaton is a grid of cells, where each cell's next state depends only on its current state and neighbors.\n\n**Conway's Game of Life rules**:\n- Live cell with 2-3 neighbors survives\n- Dead cell with exactly 3 neighbors becomes alive\n- All other cells die\n\n### Why Cellular Automata Matter\n\nDespite their simplicity, CA exhibit **emergent complexity** — complex global patterns arise from simple local rules. This is the same principle behind:\n- **Biological morphogenesis**: How a single cell (embryo) grows into a complex organism using only local chemical signals\n- **Swarm intelligence**: How ant colonies build complex structures with no central coordinator\n- **Self-organization**: How crystals, snowflakes, and neural patterns form\n\nThe key insight is that **local rules + iteration = global structure**. Neural CA take this further by *learning* the local rules from data instead of hand-designing them."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_of_life_step(grid: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"One step of Conway's Game of Life.\"\"\"\n",
    "    kernel = torch.tensor([[1, 1, 1],\n",
    "                          [1, 0, 1],\n",
    "                          [1, 1, 1]], dtype=torch.float32)\n",
    "    kernel = kernel.view(1, 1, 3, 3)\n",
    "    \n",
    "    grid_4d = grid.float().view(1, 1, *grid.shape)\n",
    "    neighbors = F.conv2d(grid_4d, kernel, padding=1).squeeze()\n",
    "    \n",
    "    birth = (grid == 0) & (neighbors == 3)\n",
    "    survive = (grid == 1) & ((neighbors == 2) | (neighbors == 3))\n",
    "    \n",
    "    return (birth | survive).float()\n",
    "\n",
    "# Create initial state with a glider\n",
    "grid_size = 32\n",
    "initial = torch.zeros(grid_size, grid_size)\n",
    "glider = torch.tensor([[0, 1, 0],\n",
    "                       [0, 0, 1],\n",
    "                       [1, 1, 1]], dtype=torch.float32)\n",
    "initial[5:8, 5:8] = glider\n",
    "\n",
    "# Run simulation\n",
    "history = [initial.clone()]\n",
    "state = initial.clone()\n",
    "for _ in range(50):\n",
    "    state = game_of_life_step(state)\n",
    "    history.append(state.clone())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, step in enumerate([0, 10, 20, 30, 50]):\n",
    "    axes[i].imshow(history[step].numpy(), cmap='binary')\n",
    "    axes[i].set_title(f'Step {step}')\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(\"Conway's Game of Life - Glider\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Making CA Differentiable\n\nTo learn CA rules, we need:\n1. **Continuous state**: Not just 0/1, but real values (so gradients can flow)\n2. **Smooth update function**: Learnable neural network (replaces hand-coded rules)\n3. **Differentiable loss**: Compare to target pattern (MSE between generated and target image)\n\n### The Multi-Channel State\n\nEach cell isn't just a single number — it has **multiple channels**:\n- **Channels 0-3**: RGBA (what we see — red, green, blue, alpha)\n- **Channels 4-15**: Hidden channels (internal state the CA uses to coordinate)\n\nThe hidden channels are like invisible \"chemical signals\" that cells pass to neighbors. Biologically, this mirrors how real cells communicate through chemical gradients (morphogens) that aren't directly visible.\n\n### The Alpha Channel as \"Alive\" Signal\n\nChannel 3 (alpha) serves as a binary alive/dead signal. A cell is \"alive\" if its alpha value (or any neighbor's alpha) exceeds a threshold. Dead cells get zeroed out. This prevents the pattern from growing infinitely and creates clear boundaries."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 16  # 4 visible (RGBA) + 12 hidden\n",
    "\n",
    "def create_seed(size: int, num_channels: int = NUM_CHANNELS) -> torch.Tensor:\n",
    "    \"\"\"Create a seed state with a single active cell in the center.\"\"\"\n",
    "    state = torch.zeros(1, num_channels, size, size)\n",
    "    center = size // 2\n",
    "    state[0, 3, center, center] = 1.0  # Alpha channel\n",
    "    return state\n",
    "\n",
    "def get_visible_state(state: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Extract RGBA channels from state.\"\"\"\n",
    "    rgba = state[:, :4, :, :]\n",
    "    return torch.clamp(rgba, 0, 1)\n",
    "\n",
    "# Visualize seed\n",
    "seed = create_seed(64)\n",
    "visible = get_visible_state(seed)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(visible[0, 3].numpy(), cmap='gray')\n",
    "plt.title('Seed State (Alpha Channel)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(f\"State shape: {seed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Perception: Sobel Filters\n\nEach cell needs to perceive its neighborhood. We use **Sobel filters** to detect gradients.\n\n### Why Sobel Filters Instead of Raw Neighbor Values?\n\nSobel filters give each cell richer information about its neighborhood:\n\n- **Identity filter**: \"What is my own value?\" (the cell's current state)\n- **Sobel-X filter**: \"Are my left neighbors different from my right neighbors?\" (horizontal gradient)\n- **Sobel-Y filter**: \"Are my top neighbors different from my bottom neighbors?\" (vertical gradient)\n\nThis is the same as asking: \"Am I at an edge? Which direction is the edge?\" — exactly the information needed to grow patterns with defined boundaries.\n\n**Connection to biology**: Real cells sense concentration gradients of signaling molecules. A cell at the edge of a tissue \"feels\" a steep gradient (lots of signal on one side, none on the other). Sobel filters are a simple mathematical model of this gradient sensing.\n\n### Why Not Just Use Raw Convolution?\n\nWe could let the network learn arbitrary 3x3 filters. But Sobel filters provide a strong inductive bias:\n- They decompose neighborhood information into interpretable components (value + gradients)\n- This reduces the number of parameters the network needs to learn\n- The perception output has `num_channels × 3` dimensions (identity + x-gradient + y-gradient for each channel)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptionModule(nn.Module):\n",
    "    \"\"\"Perceive local neighborhood using Sobel filters.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels: int = NUM_CHANNELS):\n",
    "        super().__init__()\n",
    "        \n",
    "        sobel_x = torch.tensor([[-1, 0, 1],\n",
    "                                [-2, 0, 2],\n",
    "                                [-1, 0, 1]], dtype=torch.float32) / 8.0\n",
    "        \n",
    "        sobel_y = torch.tensor([[-1, -2, -1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 2, 1]], dtype=torch.float32) / 8.0\n",
    "        \n",
    "        identity = torch.tensor([[0, 0, 0],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 0]], dtype=torch.float32)\n",
    "        \n",
    "        filters = torch.stack([identity, sobel_x, sobel_y])\n",
    "        self.filters = nn.Parameter(\n",
    "            filters.repeat(num_channels, 1, 1).view(-1, 1, 3, 3),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        self.num_channels = num_channels\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        perceived = F.conv2d(x, self.filters, padding=1, groups=self.num_channels)\n",
    "        return perceived\n",
    "\n",
    "# Demonstrate perception\n",
    "perception = PerceptionModule()\n",
    "test_state = torch.zeros(1, NUM_CHANNELS, 32, 32)\n",
    "test_state[0, 3, 10:22, 10:22] = 1.0\n",
    "\n",
    "perceived = perception(test_state)\n",
    "print(f\"Input shape: {test_state.shape}\")\n",
    "print(f\"Perceived shape: {perceived.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Neural CA Update Rule\n\n### Architecture Design Choices\n\nThe update network uses **1x1 convolutions** — these are equivalent to applying the same MLP to every cell independently. This enforces **spatial uniformity**: every cell uses the exact same update rule, just like in classical CA.\n\n**Key design decisions**:\n- **Zero-initialized last layer**: The update starts as \"do nothing\" (delta = 0). This means the model starts stable and gradually learns to make changes — much easier to train than starting with random updates.\n- **Stochastic update mask**: During training, only a random subset of cells update each step. This forces cells to be robust to neighbors updating at different times, which is critical for stable long-term growth and regeneration.\n- **Residual connection**: The update is additive (`state = state + delta`), not a replacement. This makes training more stable and allows small, incremental changes.\n- **Alive masking**: Cells that are \"dead\" (alpha < threshold) are forced to zero. This prevents patterns from growing infinitely and creates sharp boundaries."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCA(nn.Module):\n",
    "    \"\"\"Neural Cellular Automaton.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels: int = NUM_CHANNELS, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_channels = num_channels\n",
    "        self.perception = PerceptionModule(num_channels)\n",
    "        \n",
    "        perception_dim = num_channels * 3\n",
    "        \n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Conv2d(perception_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, num_channels, 1),\n",
    "        )\n",
    "        \n",
    "        nn.init.zeros_(self.update_net[-1].weight)\n",
    "        nn.init.zeros_(self.update_net[-1].bias)\n",
    "    \n",
    "    def get_alive_mask(self, state: torch.Tensor, threshold: float = 0.1) -> torch.Tensor:\n",
    "        alpha = state[:, 3:4, :, :]\n",
    "        alive = F.max_pool2d(alpha, 3, stride=1, padding=1) > threshold\n",
    "        return alive.float()\n",
    "    \n",
    "    def forward(self, state: torch.Tensor, update_rate: float = 0.5) -> torch.Tensor:\n",
    "        pre_alive = self.get_alive_mask(state)\n",
    "        perceived = self.perception(state)\n",
    "        delta = self.update_net(perceived)\n",
    "        \n",
    "        if self.training:\n",
    "            update_mask = (torch.rand_like(state[:, :1, :, :]) < update_rate).float()\n",
    "        else:\n",
    "            update_mask = 1.0\n",
    "        \n",
    "        state = state + delta * update_mask\n",
    "        post_alive = self.get_alive_mask(state)\n",
    "        alive_mask = pre_alive * post_alive\n",
    "        state = state * alive_mask\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def run_steps(self, state: torch.Tensor, steps: int) -> torch.Tensor:\n",
    "        for _ in range(steps):\n",
    "            state = self(state)\n",
    "        return state\n",
    "\n",
    "nca = NeuralCA().to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in nca.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Training to Grow a Pattern\n\n### Pool-Based Training (Why It's Necessary)\n\nNaive training (always start from seed, grow for N steps, compute loss) has a problem: the model only learns to grow from a fresh seed. It doesn't learn to **persist** or **recover from damage**.\n\nPool-based training solves this:\n1. Maintain a pool of N states (e.g., 256), initialized as seeds\n2. Sample a batch from the pool (these could be partially-grown states from previous iterations)\n3. Run for a random number of steps (64-96, not fixed — prevents the model from \"memorizing\" a specific step count)\n4. Compute loss against target and backpropagate\n5. Put the updated states back in the pool (so next iteration starts from where we left off)\n6. Replace the worst-performing sample with a fresh seed (prevents the pool from degrading)\n\n**Why this works**: The model is trained on states at all stages of growth (fresh seeds, partially grown, fully grown), so it learns a stable attractor that works regardless of starting state.\n\n### Training Stability Tips\n\n- **Gradient clipping** (1.0): NCA can have exploding gradients because errors compound over many steps\n- **Random step counts** (64-96): Prevents overfitting to a fixed number of steps\n- **Pool replacement**: Injecting fresh seeds prevents the pool from becoming stale\n- **Learning rate**: Start with 2e-3 (Adam), which is higher than typical deep learning because the model is small"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_circle(size: int = 64) -> torch.Tensor:\n",
    "    \"\"\"Create a simple circle target pattern.\"\"\"\n",
    "    target = torch.zeros(1, 4, size, size)\n",
    "    center = size // 2\n",
    "    \n",
    "    y, x = torch.meshgrid(torch.arange(size), torch.arange(size), indexing='ij')\n",
    "    y, x = y.float(), x.float()\n",
    "    \n",
    "    dist_from_center = torch.sqrt((x - center)**2 + (y - center)**2)\n",
    "    circle_radius = size * 0.35\n",
    "    circle_mask = dist_from_center < circle_radius\n",
    "    \n",
    "    target[0, 0][circle_mask] = 1.0  # R\n",
    "    target[0, 1][circle_mask] = 0.5  # G\n",
    "    target[0, 2][circle_mask] = 0.0  # B\n",
    "    target[0, 3][circle_mask] = 1.0  # A\n",
    "    \n",
    "    return target\n",
    "\n",
    "target = create_target_circle(64).to(device)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "img = target[0].permute(1, 2, 0).cpu().numpy()\n",
    "plt.imshow(img)\n",
    "plt.title('Target Pattern')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nca(model, target, num_epochs=500, pool_size=256, batch_size=4, lr=2e-3):\n",
    "    \"\"\"Train NCA using a pool of states.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    size = target.shape[-1]\n",
    "    pool = create_seed(size).repeat(pool_size, 1, 1, 1).to(device)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        batch_indices = torch.randint(0, pool_size, (batch_size,))\n",
    "        batch = pool[batch_indices].clone()\n",
    "        num_steps = torch.randint(64, 96, (1,)).item()\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            batch = model(batch)\n",
    "        \n",
    "        visible = get_visible_state(batch)\n",
    "        loss = F.mse_loss(visible, target.expand(batch_size, -1, -1, -1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pool[batch_indices] = batch.detach()\n",
    "            batch_losses = F.mse_loss(visible, target.expand(batch_size, -1, -1, -1), reduction='none')\n",
    "            batch_losses = batch_losses.mean(dim=(1, 2, 3))\n",
    "            worst_idx = batch_indices[batch_losses.argmax()]\n",
    "            pool[worst_idx] = create_seed(size).to(device).squeeze(0)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "nca = NeuralCA().to(device)\n",
    "print(\"Training Neural CA...\")\n",
    "losses = train_nca(nca, target, num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_growth(model, size=64, steps=100):\n",
    "    \"\"\"Visualize the NCA growing from seed.\"\"\"\n",
    "    model.eval()\n",
    "    state = create_seed(size).to(device)\n",
    "    history = [get_visible_state(state).cpu()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            state = model(state)\n",
    "            history.append(get_visible_state(state).cpu())\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 6, figsize=(15, 3))\n",
    "    for i, step in enumerate([0, 20, 40, 60, 80, 100]):\n",
    "        img = history[step][0].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Step {step}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('NCA Growth from Seed')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_growth(nca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Regeneration: Self-Repair from Damage\n\n### Why Regeneration Emerges Naturally\n\nRegeneration isn't explicitly trained — it emerges as a side effect of the training procedure:\n\n1. **Local rules**: Each cell only sees its 3x3 neighborhood. It doesn't know about the global pattern. It just follows its local update rule.\n2. **Same rule everywhere**: Every cell runs the identical neural network. There's no \"center cell\" with special instructions.\n3. **Pool-based training**: The model sees partially-damaged states during training (when pool samples are at different stages of growth). This implicitly teaches recovery.\n4. **Stable attractor**: The target pattern is a fixed point of the learned dynamics. Any perturbation (damage) is corrected because the local rules push the state back toward the attractor.\n\n**Analogy**: Imagine a crowd of people, each following the rule \"stand 2 feet from your nearest neighbor.\" If you remove a few people, the remaining crowd naturally fills the gaps — not because anyone was told to, but because the local rule creates a stable global configuration.\n\n### Connection to Biological Regeneration\n\nReal organisms (like salamanders regrowing limbs) use similar principles:\n- Cells communicate only with neighbors (chemical signals)\n- Every cell runs the same DNA \"program\"\n- The target pattern (body plan) is encoded as a stable attractor of the cell dynamics\n- Damage disrupts the local state, and the local rules drive recovery\n\nNeural CA provide a simplified computational model of this biological process."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regeneration(model, size=64, grow_steps=100, regen_steps=100):\n",
    "    \"\"\"Test NCA regeneration after damage.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    state = create_seed(size).to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(grow_steps):\n",
    "            state = model(state)\n",
    "    \n",
    "    grown = state.clone()\n",
    "    damaged = state.clone()\n",
    "    damaged[:, :, 20:44, 20:44] = 0\n",
    "    \n",
    "    regenerating = damaged.clone()\n",
    "    regen_history = [get_visible_state(regenerating).cpu()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(regen_steps):\n",
    "            regenerating = model(regenerating)\n",
    "            regen_history.append(get_visible_state(regenerating).cpu())\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    axes[0, 0].imshow(get_visible_state(grown)[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 0].set_title('Fully Grown')\n",
    "    axes[0, 1].imshow(get_visible_state(damaged)[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0, 1].set_title('After Damage')\n",
    "    for i in range(3):\n",
    "        axes[0, i+2].axis('off')\n",
    "    \n",
    "    for i, step in enumerate([0, 25, 50, 75, 100]):\n",
    "        axes[1, i].imshow(regen_history[step][0].permute(1, 2, 0).numpy())\n",
    "        axes[1, i].set_title(f'Regen Step {step}')\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('NCA Regeneration After Damage')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_regeneration(nca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Concepts to Know\n\n### Classical CA vs Neural CA\n\n| Aspect | Classical CA (Game of Life) | Neural CA |\n|--------|---------------------------|-----------|\n| Rules | Hand-designed, fixed | Learned via gradient descent |\n| State | Discrete (0/1) | Continuous (real-valued) |\n| Trainable | No | Yes (differentiable) |\n| Complexity | Limited by rule design | Can learn arbitrary patterns |\n| Channels | 1 | 16+ (hidden channels for coordination) |\n\n### Why Sobel Filters for Perception?\n\nSobel filters detect gradients in the neighborhood. They give each cell three pieces of information per channel:\n- **Identity**: \"What is my current value?\"\n- **Sobel-X**: \"What is the horizontal gradient?\" (left-right difference)\n- **Sobel-Y**: \"What is the vertical gradient?\" (top-bottom difference)\n\nThis is computationally cheap and biologically inspired — real cells sense chemical concentration gradients to determine their position and role during development.\n\n### How Pool-Based Training Works\n\nThe pool is like a \"memory\" of training states. Instead of always starting from a fresh seed, the model trains on states at various stages of development. This teaches:\n- **Growth**: How to develop from a seed\n- **Persistence**: How to maintain a stable pattern\n- **Recovery**: How to heal from partial damage (because pool states can be \"partially grown\")\n\n### Why NCAs Regenerate\n\nThe target pattern becomes a **stable attractor** of the learned dynamics:\n- Local rules push any perturbed state back toward the target\n- No cell \"knows\" the global pattern — regeneration is purely emergent\n- The same principle explains biological regeneration in organisms like planaria and salamanders\n\n### Applications of Neural CA\n\n- **Texture synthesis**: Generate seamless textures from small examples\n- **Pattern growth**: Grow complex images from single-pixel seeds\n- **Self-repairing systems**: Distributed systems that recover from component failure\n- **Morphogenesis modeling**: Understanding how organisms develop from embryos\n- **Generative art**: Creating organic, evolving visual artworks\n- **Decentralized computing**: Algorithms with no central controller, robust to local failures"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "1. **Neural CA** combine cellular automata with learnable neural networks\n",
    "2. **Perception** uses Sobel filters to sense local gradients\n",
    "3. **Update rule** is a small network applied to each cell\n",
    "4. **Residual updates** with stochastic masks enable stable growth\n",
    "5. **Pool-based training** tests persistence and robustness\n",
    "6. **Regeneration** emerges naturally from local rules\n",
    "7. **Self-organization** produces complex patterns from simple seeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}