{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: Advanced Topics and Best Practices\n",
    "\n",
    "Saving/loading models, GPU usage, transfer learning, and debugging.\n",
    "\n",
    "## Learning Objectives\n",
    "- Save and load trained models\n",
    "- Use GPU acceleration\n",
    "- Transfer learning basics\n",
    "- Debugging tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check available devices\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon GPU) is available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Save entire model\n",
    "torch.save(model, \"model.pth\")\n",
    "print(\"Saved entire model\")\n",
    "\n",
    "# Save only state dict (recommended)\n",
    "torch.save(model.state_dict(), \"model_state.pth\")\n",
    "print(\"Saved state dict\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = torch.load(\"model.pth\")\n",
    "print(\"Loaded entire model\")\n",
    "\n",
    "# Load state dict\n",
    "new_model = SimpleModel()\n",
    "new_model.load_state_dict(torch.load(\"model_state.pth\"))\n",
    "print(\"Loaded state dict\")\n",
    "\n",
    "# Clean up\n",
    "import os\n",
    "os.remove(\"model.pth\")\n",
    "os.remove(\"model_state.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best device (MPS > CUDA > CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon GPU\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPU fallback\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = SimpleModel()\n",
    "model = model.to(device)\n",
    "print(f\"Model on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Move data to device\n",
    "x = torch.randn(5, 10).to(device)\n",
    "print(f\"Data on: {x.device}\")\n",
    "\n",
    "# Compute on device\n",
    "output = model(x)\n",
    "print(f\"Output computed on: {output.device}\")\n",
    "\n",
    "# Note: For Apple Silicon Macs, use 'mps' instead of 'cuda'\n",
    "# Both work the same way: model.to('mps'), tensor.to('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "from torchvision import models\n",
    "\n",
    "# Load pretrained ResNet\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "print(\"Loaded pretrained ResNet18\")\n",
    "\n",
    "# Freeze early layers\n",
    "for param in list(resnet.parameters())[:-2]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify last layer for new task (e.g., 10 classes instead of 1000)\n",
    "num_classes = 10\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "print(f\"Modified for {num_classes} classes\")\n",
    "\n",
    "# Only new layer will be trained\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in resnet.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Always set model to eval() for inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "\n",
    "# 2. Use DataLoader for batching\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 3. Use learning rate scheduling\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 4. Gradient clipping (prevents exploding gradients)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "# 5. Check for NaN/Inf\n",
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"NaN in {name}\")\n",
    "\n",
    "print(\"Best practices demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common issues and solutions:\n",
    "print(\"1. Loss not decreasing:\")\n",
    "print(\"   - Check learning rate (try 0.001, 0.0001)\")\n",
    "print(\"   - Verify data is correct\")\n",
    "print(\"   - Check model architecture\")\n",
    "print()\n",
    "print(\"2. Out of memory:\")\n",
    "print(\"   - Reduce batch size\")\n",
    "print(\"   - Use gradient accumulation\")\n",
    "print(\"   - Clear cache:\")\n",
    "print(\"     * CUDA: torch.cuda.empty_cache()\")\n",
    "print(\"     * MPS: torch.mps.empty_cache()\")\n",
    "print()\n",
    "print(\"3. Model not learning:\")\n",
    "print(\"   - Check if gradients are computed: param.grad is not None\")\n",
    "print(\"   - Verify loss function\")\n",
    "print(\"   - Check data normalization\")\n",
    "print()\n",
    "print(\"4. Overfitting:\")\n",
    "print(\"   - Add dropout\")\n",
    "print(\"   - Use data augmentation\")\n",
    "print(\"   - Reduce model complexity\")\n",
    "print(\"   - Early stopping\")\n",
    "print()\n",
    "print(\"5. MPS-specific (Apple Silicon):\")\n",
    "print(\"   - Some operations may not be supported on MPS\")\n",
    "print(\"   - If you get MPS errors, fall back to CPU: tensor.cpu()\")\n",
    "print(\"   - MPS is generally faster for large models and datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Save models**: Use state_dict for portability\n",
    "2. **GPU Acceleration**: \n",
    "   - **CUDA**: NVIDIA GPUs (Windows/Linux)\n",
    "   - **MPS**: Apple Silicon GPUs (M1/M2/M3 Macs)\n",
    "   - Move model and data to device for speed\n",
    "3. **Transfer Learning**: Use pretrained models for new tasks\n",
    "4. **Best Practices**: eval(), no_grad(), schedulers, clipping\n",
    "5. **Debugging**: Check gradients, learning rate, data\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the PyTorch tutorial series! ðŸŽ‰\n",
    "\n",
    "You now know:\n",
    "- Tensors and operations\n",
    "- Automatic differentiation\n",
    "- Building neural networks\n",
    "- Training models\n",
    "- Practical applications\n",
    "- Advanced techniques\n",
    "\n",
    "**Keep practicing and building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}